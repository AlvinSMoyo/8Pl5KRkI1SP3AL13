{"cells":[{"cell_type":"markdown","metadata":{"id":"tt2bjaU5RtQr"},"source":["# **Term Deposit Marketing Project**\n","\n","## ðŸ“Œ Project Overview & Objective\n","\n","This project aims to optimize customer targeting for term deposit subscriptions using a two-phase modeling strategy:\n","- **Pre-Call Phase** â€“ Identify customers unlikely to subscribe before any contact is made.\n","- **Post-Call Phase** â€“ Predict likelihood of subscription based on call interaction metadata.\n","\n","---\n","#### **Background**:\n","\n","We are a small startup focusing mainly on providing machine learning solutions in the European banking market. We work on a variety of problems including fraud detection, sentiment classification and customer intention prediction and classification.\n","\n","We are interested in developing a robust machine learning system that leverages information coming from call center data.\n","\n","Ultimately, we are looking for ways to improve the success rate for calls made to customers for any product that our clients offer. Towards this goal we are working on designing an ever evolving machine learning product that offers high success outcomes while offering interpretability for our clients to make informed decisions.\n","\n","#### **Data Description**:\n","\n","The data comes from direct marketing efforts of a European banking institution. The marketing campaign involves making a phone call to a customer, often multiple times to ensure a product subscription, in this case a term deposit. Term deposits are usually short-term deposits with maturities ranging from one month to a few years. The customer must understand when buying a term deposit that they can withdraw their funds only after the term ends. All customer information that might reveal personal information is removed due to privacy concerns.\n","\n","#### **Attributes:**\n","\n","age : age of customer (numeric)\n","\n","job : type of job (categorical)\n","\n","marital : marital status (categorical)\n","\n","education (categorical)\n","\n","default: has credit in default? (binary)\n","\n","balance: average yearly balance, in euros (numeric)\n","\n","housing: has a housing loan? (binary)\n","\n","loan: has personal loan? (binary)\n","\n","contact: contact communication type (categorical)\n","\n","day: last contact day of the month (numeric)\n","\n","month: last contact month of year (categorical)\n","\n","duration: last contact duration, in seconds (numeric)\n","\n","campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n","\n","Output (desired target):\n","\n","y - has the client subscribed to a term deposit? (binary)\n","\n","#### **Download Data**:\n","\n","https://drive.google.com/file/d/1EW-XMnGfxn-qzGtGPa3v_C63Yqj2aGf7\n","\n","#### **Goal(s):**\n","\n","Predict if the customer will subscribe (yes/no) to a term deposit (variable y)\n","\n","#### **Success Metric(s):**\n","\n","Hit %81 or above accuracy by evaluating with 5-fold cross validation and reporting the average performance score.\n","\n","#### **Current Challenges:**\n","\n","We are also interested in finding customers who are more likely to buy the investment product. Determine the segment(s) of customers our client should prioritize.\n","\n","What makes the customers buy? Tell us which feature we should be focusing more on."]},{"cell_type":"markdown","source":["## ðŸ“š Table of Contents\n","\n","- ðŸ“Œ [Project Overview & Objective](#project-overview--objective)\n","- ðŸ“š [Table of Contents](#table-of-contents)\n","- ðŸ§° [Initial Setup & Dataset Description](#initial-setup--dataset-description)\n","- ðŸ“Š [Exploratory Data Analysis (EDA)](#exploratory-data-analysis-eda)\n","- ðŸ› ï¸ [Feature Engineering & Cleaning](#feature-engineering--cleaning)\n","- ðŸ§ª [Pre-Call Modeling Workflow](#pre-call-modeling-workflow)\n","  - ðŸ [Classifier Benchmarking](#pre-call-classifier-benchmarking)\n","  - ðŸŽ¯ [Cross-Validation Evaluation](#pre-call-cross-validation-evaluation)\n","  - ðŸŽ¯ [Threshold Search & Tuning](#pre-call-threshold-search--tuning)\n","  - ðŸŽ¯ [Validation Confusion Matrix Analysis](#pre-call-validation-confusion-matrix-analysis)\n","  - ðŸŽ¯ [Test Set Confusion Matrix Analysis](#pre-call-test-set-confusion-matrix-analysis)\n","  - â±ï¸ [Time Efficiency Analysis](#pre-call-time-efficiency-analysis-of-final-model)\n","  - ðŸ§  [Traditional Segment Analysis](#pre-call-traditional-segment-analysis)\n","  - ðŸ” [Segment Profiling & Clustering Insights](#pre-call-segment-profiling--clustering-insights-optional)\n","  - ðŸ“ [Final Round-Up](#pre-call-final-round-up)\n","- ðŸ“ž [Post-Call Modeling Workflow](#post-call-modeling-workflow)\n","  - ðŸ› ï¸ [Feature Set Definition & Preprocessing](#post-call-feature-set-definition--preprocessing)\n","  - ðŸ [Initial Model Benchmarking](#post-call-initial-model-benchmarking)\n","  - ðŸ”§ [Hyperparameter Tuning](#post-call-hyperparameter-tuning-of-selected-models)\n","  - ðŸŽ¯ [Threshold Search & Tuning](#post-call-threshold-search--tuning)\n","  - ðŸŽ¯ [Test Set Evaluation & Confusion Matrix](#post-call-test-set-evaluation--confusion-matrix)\n","  - â±ï¸ [Time Efficiency Analysis](#post-call-time-efficiency-analysis)\n","  - ðŸ”¥ [Feature Importance Analysis](#post-call-feature-importance-analysis)\n","  - ðŸ“‹ [Post-Call Clustering & Segment Summary](#post-call-clustering--segment-summary)\n","- ðŸš€ [DuckDB Optimization (Bonus)](#duckdb-optimization-bonus)\n","- ðŸ“‹ [Cluster Visualization Findings (PCA, t-SNE, UMAP)](#cluster-visualization-findings-pca-t-sne-umap)\n","- ðŸ“Œ [Post-Call Phase Summary](#post-call-phase-summary)\n","- ðŸ’¼ [Final Project Conclusion & Business Recommendations](#final-project-conclusion--business-recommendations)\n","\n","---"],"metadata":{"id":"hRBFxiZto0YZ"}},{"cell_type":"markdown","source":["## ðŸ§° Initial Setup & Dataset Description\n","\n","- Load the dataset and establish a reproducible random seed (`1208`).\n","- Perform basic inspection of structure and schema.\n","- Prepare environment by installing required libraries."],"metadata":{"id":"IAGcs7kdvXuZ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"4WzN_is1RfHQ"},"outputs":[],"source":["# Installing libraries with specified versions\n","!pip install numpy==1.25.2 pandas==1.5.3 scikit-learn==1.2.2 matplotlib==3.7.1 seaborn==0.13.1 xgboost==2.0.3 imbalanced-learn==0.10.1 statsmodels==0.14.1 eli5 duckdb umap-learn -q --user"]},{"cell_type":"code","source":["#        --- Libraries to be used throughout ---\n","\n","# Libraries to help with reading and manipulating data\n","import pandas as pd\n","import numpy as np\n","\n","# Libaries to help with data visualization\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import eli5\n","from eli5.sklearn import PermutationImportance\n","import duckdb\n","import umap\n","\n","# To tune models, get different metric scores and displays\n","from sklearn.metrics import (\n","    make_scorer,\n","    f1_score,\n","    accuracy_score,\n","    recall_score,\n","    precision_score,\n","    confusion_matrix,\n","    roc_auc_score,\n","    precision_recall_fscore_support,\n","    average_precision_score\n",")\n","from sklearn.metrics import (\n","    roc_curve,\n","    precision_recall_curve,\n","    RocCurveDisplay,\n","    PrecisionRecallDisplay,\n","    auc,\n","    classification_report,\n","    ConfusionMatrixDisplay\n",")\n","\n","from sklearn.decomposition import PCA\n","from sklearn.manifold import TSNE\n","from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n","\n","# To get different performance metrics\n","from sklearn.inspection import permutation_importance\n","\n","# To be used for data scaling and preprocessing\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder, RobustScaler\n","\n","# To be used for creating pipelines and personalizing them\n","from sklearn.pipeline import (\n","    Pipeline,\n","    Pipeline as ImbPipeline\n",")\n","# To transform columns\n","from sklearn.compose import ColumnTransformer\n","\n","# To impute missing values\n","from sklearn.impute import SimpleImputer, KNNImputer\n","\n","# To sample data\n","from imblearn.over_sampling import SMOTE\n","from imblearn.over_sampling import BorderlineSMOTE\n","from imblearn.under_sampling import RandomUnderSampler\n","from imblearn.over_sampling import ADASYN\n","\n","# To split data, model selection and tuning\n","from sklearn.model_selection import (\n","     RandomizedSearchCV,\n","     train_test_split,\n","     StratifiedKFold,\n","     cross_val_score,\n","     cross_validate,\n","     GridSearchCV\n",")\n","\n","# Classifiers to help with model building\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.naive_bayes import BernoulliNB, ComplementNB\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.svm import SVC\n","from sklearn.ensemble import (\n","    GradientBoostingClassifier,\n","    RandomForestClassifier,\n","    StackingClassifier,\n","    VotingClassifier\n",")\n","from xgboost import XGBClassifier\n","\n","# To suppress scientific notations\n","pd.set_option('display.float_format', lambda x: '%.3f' % x)\n","\n","# To suppress warnings\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","# to get random seed\n","import random\n","\n","# to save models\n","import joblib\n","from joblib import dump, load"],"metadata":{"id":"qm0QfE0PJ-F5"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cwFtefS_SBSV"},"outputs":[],"source":["# Loading the DataSet\n","term_deposit = pd.read_csv('term-deposit-marketing-2020.csv')"]},{"cell_type":"markdown","metadata":{"id":"WOXKPu8fSG08"},"source":["- `seed = random.randint(1000, 9999)`\n","- `print(seed)`\n","  - `Output=1208`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mx1ObRwWSZ50"},"outputs":[],"source":["#    --- Fixing Random Seed ---\n","\n","# define the seed\n","seed = 1208\n","random.seed(seed) #set seed for random module\n","np.random.seed(seed) # set seed for NumPy\n","\n","print(f'Random Seed: {seed}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0wDdfH7eS3pQ"},"outputs":[],"source":["# Copying data to another varaible to avoid changes to original data\n","data = term_deposit.copy()"]},{"cell_type":"code","source":["# checking shape of the data\n","def get_num_rows(data): return data.shape[0]\n","def get_num_cols(data): return data.shape[1]\n","print(f'There are {get_num_rows(data)} rows and {get_num_cols(data)} columns in the dataset.')"],"metadata":{"id":"ik0zoHVY8I16"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","## ðŸ“Š Exploratory Data Analysis (EDA)\n","\n","- Preview dataset structure and first records.\n","- Understand basic attribute types, and initial patterns.\n","- Understand customer demographics, product preferences, and campaign behavior.\n","- Detect class imbalance and identify early signal patterns."],"metadata":{"id":"fjWnkWgg8iNw"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"5cNTfIugS7pq"},"outputs":[],"source":["# View the first five rows of the data\n","data.head()"]},{"cell_type":"markdown","source":["At 1st glance, the data loaded correctly. It shows different attributes of data collected in a marketing campaign to a customers for them to subscribe to term deposit banking products."],"metadata":{"id":"Ub6TYSOyUMUL"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"h999HE1pS_Tr"},"outputs":[],"source":["# Viewing a random sample of the dataset\n","data.sample(n=7, random_state=seed)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7kTEXuXrTKv4"},"outputs":[],"source":["# Checking the data types of the columns in the dataset\n","data.info()"]},{"cell_type":"markdown","source":["- The dependent variable `y` is of object type.\n","- There is a total of 9 object type columns all categorical, including the predictable variable.\n","- There are 5 integer type numeric columns.\n","- All 14 columns in the dataset have a full compliment of 40,000 values."],"metadata":{"id":"saXzb_m9Vc1R"}},{"cell_type":"markdown","source":["### ðŸ“ˆ Statistical Analysis"],"metadata":{"id":"JmQfD0mLd3K9"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"071EzW5iTNFw"},"outputs":[],"source":["# Statistical Summary of Numerical Data\n","data.describe().T"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"654nd_qZTPr0"},"outputs":[],"source":["# Statistical summary of object columns\n","data.describe(include='object').T"]},{"cell_type":"markdown","source":["### ðŸ§¾ Descriptive Statistical Summary\n","\n","A snapshot of key statistics from the dataset:\n","\n","- **Customer Age Range:** 19 to 95 years.\n","- **Average Account Balance:** ~â‚¬2,904. However, 75% of customers have balances **below this mean**, suggesting the presence of **extreme positive outliers**.\n","- **Longest Call Duration:** ~82 minutes â€” a significant outlier among call durations.\n","- **Most Intensive Campaign:** Up to **63 contacts** were made to a single customer.\n","- **Dominant Job Category:** **Blue-collar** workers make up the largest job group in the dataset.\n","- **Binary Variables:** The features `default`, `housing`, `loan`, and `y` all contain **binary values** (`yes` or `no`).\n","- **Primary Contact Method:** **Cellular phones** are the most common, used to reach **24,914 out of 40,000** customers.\n","- **Subscription Outcome:** A striking **37,104 out of 40,000** customers said **\"no\"** to subscribing â€” emphasizing the datasetâ€™s **imbalance** and the challenge of predicting \"yes\" responses.\n","\n","---"],"metadata":{"id":"YPVEa20TXNAS"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"5pxY3j-CTXFb"},"outputs":[],"source":["# making a list of all catrgorical variables\n","data.select_dtypes(include='object').columns\n","\n","# printing number of count of each unique value in each column\n","for col in data.select_dtypes(include='object').columns:\n","    print(data[col].value_counts())\n","    print('~' *45)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hr62kMirTh5q"},"outputs":[],"source":["#       --- Funtion to create boxplots and histograms on same scale ---\n","def histogram_boxplot(data, feature, figsize=(15, 10), kde=False, bins=None):\n","    '''\n","    Boxplot and histogram combined\n","\n","    data: dataframe\n","    feature: dataframe column\n","    figsize: size of figure (default (15,10))\n","    kde: whether to show the density curve (default False)\n","    bins: number of bins for histogram (default None)\n","    '''\n","    f2, (ax_box2, ax_hist2) = plt.subplots(\n","        nrows=2,  # Number of rows of the subplot grid= 2\n","        sharex=True,  # x-axis will be shared among all subplots\n","        gridspec_kw={'height_ratios': (0.25, 0.75)},\n","        figsize=figsize,\n","    )  # creating the 2 subplots\n","    sns.boxplot(\n","        data=data, x=feature, ax=ax_box2, showmeans=True, color='violet'\n","    )  # boxplot will be created and a triangle will indicate the mean value of the column\n","    sns.histplot(\n","        data=data, x=feature, kde=kde, ax=ax_hist2, bins=bins\n","    ) if bins else sns.histplot(\n","        data=data, x=feature, kde=kde, ax=ax_hist2\n","    )  # For histogram\n","    ax_hist2.axvline(\n","        data[feature].mean(), color='green', linestyle='--'\n","    )  # Add mean to the histogram\n","    ax_hist2.axvline(\n","        data[feature].median(), color='black', linestyle='-'\n","    )  # Add median to the histogram"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Rm_SXkbGThLv"},"outputs":[],"source":["#     --- Function to create labeled barplots ---\n","def labeled_barplot(data, feature, perc=False, n=None):\n","    '''\n","    Barplot with percentage at the top\n","\n","    data: dataframe\n","    feature: dataframe column\n","    perc: whether to display percentages instead of count (default is False)\n","    n: displays the top n category levels (default is None, i.e., display all levels)\n","    '''\n","\n","    total = len(data[feature])  # length of the column\n","    count = data[feature].nunique()\n","    if n is None:\n","        plt.figure(figsize=(count + 2, 6))\n","    else:\n","        plt.figure(figsize=(n + 2, 6))\n","\n","    plt.xticks(rotation=90, fontsize=15)\n","    ax = sns.countplot(\n","        data=data,\n","        x=feature,\n","        palette='Paired',\n","        order=data[feature].value_counts().index[:n].sort_values(),\n","    )\n","\n","    for p in ax.patches:\n","        if perc == True:\n","            label = '{:.1f}%'.format(\n","                100 * p.get_height() / total\n","            )  # percentage of each class of the category\n","        else:\n","            label = p.get_height()  # count of each level of the category\n","\n","        x = p.get_x() + p.get_width() / 2  # width of the plot\n","        y = p.get_height()  # height of the plot\n","\n","        ax.annotate(\n","            label,\n","            (x, y),\n","            ha='center',\n","            va='center',\n","            size=12,\n","            xytext=(0, 5),\n","            textcoords='offset points',\n","        )  # annotate the percentage\n","\n","    plt.show()  # show the plot"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2mqoOzCGThB-"},"outputs":[],"source":["#      --- Function to plot barplot wrt target ---\n","def stacked_barplot(data, predictor, target):\n","    '''\n","    Print the category counts and plot a stacked bar chart\n","\n","    data: dataframe\n","    predictor: independent variable\n","    target: target variable\n","    '''\n","    count = data[predictor].nunique()\n","    sorter = data[target].value_counts().index[-1]\n","    tab1 = pd.crosstab(data[predictor], data[target], margins=True).sort_values(\n","        by=sorter, ascending=False\n","    )\n","    print(tab1)\n","    print('-' * 120)\n","    tab = pd.crosstab(data[predictor], data[target], normalize='index').sort_values(\n","        by=sorter, ascending=False\n","    )\n","    tab.plot(kind='bar', stacked=True, figsize=(count + 5, 5))\n","    plt.legend(\n","        loc='lower left', frameon=False,\n","    )\n","    plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n","    plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kpUgegYvTgdo"},"outputs":[],"source":["#      --- Function to plot distributions wrt target ---\n","def distribution_plot_wrt_target(data, predictor, target):\n","\n","    fig, axs = plt.subplots(2, 2, figsize=(12, 10))\n","\n","    target_uniq = data[target].unique()\n","\n","    axs[0, 0].set_title('Distribution of target for target=' + str(target_uniq[0]))\n","    sns.histplot(\n","        data=data[data[target] == target_uniq[0]],\n","        x=predictor,\n","        kde=True,\n","        ax=axs[0, 0],\n","        color='teal',\n","        stat='density',\n","    )\n","\n","    axs[0, 1].set_title('Distribution of target for target=' + str(target_uniq[1]))\n","    sns.histplot(\n","        data=data[data[target] == target_uniq[1]],\n","        x=predictor,\n","        kde=True,\n","        ax=axs[0, 1],\n","        color='orange',\n","        stat='density',\n","    )\n","\n","    axs[1, 0].set_title('Boxplot w.r.t target')\n","    sns.boxplot(data=data, x=target, y=predictor, ax=axs[1, 0], palette='gist_rainbow')\n","\n","    axs[1, 1].set_title('Boxplot (without outliers) w.r.t target')\n","    sns.boxplot(\n","        data=data,\n","        x=target,\n","        y=predictor,\n","        ax=axs[1, 1],\n","        showfliers=False,\n","        palette='gist_rainbow',\n","    )\n","\n","    plt.tight_layout()\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-fdtWbGpT3eW"},"outputs":[],"source":["# The distribution of age of customer\n","histogram_boxplot(data, 'age')"]},{"cell_type":"markdown","source":["Age of Customer - `age`\n","- Age is right skewed (unlike the general popultion which is normally distributed), due to the fact that the youngest customer is 19 and the oldest 95. We see a couple of outliers on the upper-end."],"metadata":{"id":"OWy2UPOyS266"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"UtkEWkKwT6Dp"},"outputs":[],"source":["# The distribution of average annual balance\n","histogram_boxplot(data, 'balance')"]},{"cell_type":"markdown","source":["Average Annual Balance (Euros) - `balance`\n","- Right skewed with a couple of accounts in negative and outliers on either ends of the spectrum."],"metadata":{"id":"RG5E5uloUPI5"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"HFZ5XnpPT5_m"},"outputs":[],"source":["# the distribution of last contact day of month\n","histogram_boxplot(data, 'day')"]},{"cell_type":"markdown","source":["Last Contact Day of Month - `day`\n","- Calls happen throughout the month most calls happen around the 20th, before slumping around the 23rd and going up towards monthend."],"metadata":{"id":"hjNShhq8bMBc"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"X6QQfBh2T54x"},"outputs":[],"source":["# the distribution of last contact call duration\n","histogram_boxplot(data, 'duration')"]},{"cell_type":"markdown","source":["Last Contact Duration (Sec) - `duration`\n","- The average call lasts 255 seconds (just above 4 minutes), but calls can last up to 82 minutes so there are many outliers on the upper tail."],"metadata":{"id":"7_YCfcAwdASM"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"SSAmMy2TT5pk"},"outputs":[],"source":["# the distribution of number of contacts in this campaign\n","histogram_boxplot(data, 'campaign')"]},{"cell_type":"markdown","source":["Frequency of Contacts made in Current Campaign - `campaign`\n","- The distribution is right skewed with almost 3 contacts being made on average there were a couple of longer contacts made in this campain with 63 being the a glaring outlier."],"metadata":{"id":"vKt5NvI3e4r1"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"9XG4zxR7T5mG"},"outputs":[],"source":["# the distribution of type of job\n","labeled_barplot(data, 'job', perc=True )"]},{"cell_type":"markdown","source":["Type of Job - `job`\n","- Most clients have blue-coller workers with 23.5%, then mananagemnt 20.4%, and technicians at 17.1%. Students are the fewest at 1.3% but we have 0.6% is unknown."],"metadata":{"id":"SM11b1pIgn9-"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"oHZMpvrpT5hn"},"outputs":[],"source":["# the distribution of marital status\n","labeled_barplot(data, 'marital', perc=True)\n"]},{"cell_type":"markdown","source":["Marital Status - `marital`\n","- 61% of the customers are married, followed by single at 27.2% then divorced at 11.8%"],"metadata":{"id":"CVTG0V7sii5Y"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"TkRKaq8FT5eF"},"outputs":[],"source":["# the distribution of level of education\n","labeled_barplot(data, 'education')"]},{"cell_type":"markdown","source":["Level of Education - `education`\n","- 20,993 customers have secondary education, with 11,206 obtaining tertiary education - 1531 did not disclose their status or it missing."],"metadata":{"id":"uaEZv8vXjMer"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"zBpyXuuhT5at"},"outputs":[],"source":["# the distribution of credit default\n","labeled_barplot(data, 'default', perc=True)"]},{"cell_type":"markdown","source":["Customer has Credit in Default - `default`\n","- Only 2% of 40,000 clients have defaulted on their credit."],"metadata":{"id":"eNyzc-llkyWz"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Kf4AHaV4T5Xm"},"outputs":[],"source":["# the distribution of housing loan\n","labeled_barplot(data, 'housing')"]},{"cell_type":"markdown","source":["Client has Mortgage or Housing Loan - `housing`\n","- The margority of the clients have a housing loan."],"metadata":{"id":"EY3oOQUvmDqY"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"5tJ0Xo0CT5UR"},"outputs":[],"source":["# the distribution of personal loan\n","labeled_barplot(data, 'loan', perc=True)"]},{"cell_type":"markdown","source":["Client has Personal Loan - `loan`\n","- Almost 83% of term deposit customers or potential clients have no personal loan."],"metadata":{"id":"MQ5jXRdXmrlm"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"BCfpcxgrT5RX"},"outputs":[],"source":["# the distribution of contact communication type\n","labeled_barplot(data, 'contact', perc=True)"]},{"cell_type":"markdown","source":["Contact Communication Type - `contact`\n","- 62.3% of the target market are reachable through cellular, but a staggering 31.9% is unknown which is worrisome."],"metadata":{"id":"0v5YjSJdnhDp"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"STi1P09FT5OV"},"outputs":[],"source":["# the distribution of last contact month\n","labeled_barplot(data, 'month')"]},{"cell_type":"markdown","source":["Last Contact Month of the Year - `month`\n","- The least last contacts are made in December and October, while May is by far the busiest month."],"metadata":{"id":"6GUL6EYloqUH"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vqs87rIIT5LH"},"outputs":[],"source":["# the distribution of target y- subscribed or not\n","labeled_barplot(data, 'y', perc=True)"]},{"cell_type":"markdown","source":["Has Client Subscribed to a Term Depost? - `y`\n","- Only 7.2% of the target population has subsribed to term deposit. This is our predictable variable where No is 0 and Yes is 1."],"metadata":{"id":"JroNe_cTpvKi"}},{"cell_type":"markdown","metadata":{"id":"KoLlHo7CUlwH"},"source":["Biviriate & Univariate Analysis"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D1ymifpWT5IH"},"outputs":[],"source":["# target variable y vs age of customer\n","distribution_plot_wrt_target(data, 'age', 'y')"]},{"cell_type":"markdown","source":["The age distribution for customers who subsricbed to term loans mirrors that of those who has not."],"metadata":{"id":"AotTilaSwat2"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"wnN10nXvT5E7"},"outputs":[],"source":["# target variable y vs average annual balance\n","distribution_plot_wrt_target(data, 'balance', 'y')"]},{"cell_type":"markdown","source":["We also see the yeses mirroring the nos for balance, even though yeses are a smaller sample."],"metadata":{"id":"80eZX_aSUqey"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"j-cLVvFNT5Bl"},"outputs":[],"source":["# target variable y vs last contact day\n","distribution_plot_wrt_target(data, 'day', 'y')"]},{"cell_type":"markdown","source":["Day shows a multimodal distribution, even when outliers are removed."],"metadata":{"id":"5eXxzAQJVI_M"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"YwaOi6z6T4-H"},"outputs":[],"source":["# target variable y vs last call duration\n","distribution_plot_wrt_target(data, 'duration', 'y')"]},{"cell_type":"markdown","source":["The removal of outliers show that nos have a much tighter distributionand the calls are much shorter."],"metadata":{"id":"FSGrRY4qWgKD"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"8h1ilNXeT46h"},"outputs":[],"source":["# target variable y vs contacts in campaign\n","distribution_plot_wrt_target(data, 'campaign', 'y')"]},{"cell_type":"markdown","source":["The distribution for nos is similar to that of yeses, even without outliers."],"metadata":{"id":"W72VRaIfYTMG"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"NeptrWT2T42k"},"outputs":[],"source":["# target variable y vs type of job\n","stacked_barplot(data, 'job', 'y')"]},{"cell_type":"markdown","source":["Though being the smallest demographic, students have most yeses relative to their population."],"metadata":{"id":"LNHT5WYFaF1N"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q1bSHdvNT4y2"},"outputs":[],"source":["# target variable y vs marital status\n","stacked_barplot(data, 'marital', 'y')"]},{"cell_type":"markdown","source":["Proportionally, single people say yes to term deposit products. In actual volumes however 1478 married said yes, vs 1027 single people on a base that favours married 11 to 9."],"metadata":{"id":"GZIsE1rbabfa"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"kkbmFzMST4vJ"},"outputs":[],"source":["# target variable y vs level of education\n","stacked_barplot(data, 'education', 'y')"]},{"cell_type":"markdown","source":["About 9% among people with tertiary education said yes, close to 7% said yes on the secondary category, and a 6% success rate for the primary population."],"metadata":{"id":"2so_5GZScn1D"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"YFn-Ou3LVU0u"},"outputs":[],"source":["# target variable y vs credit default\n","stacked_barplot(data, 'default', 'y')"]},{"cell_type":"markdown","source":["About 93% of non-defaulters have not subscribed, while ~6% of the very small population of defaulters have subscribed."],"metadata":{"id":"pHlUE1IKfTz_"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"wZpy8yuGVUw4"},"outputs":[],"source":["# target variable y vs has housing loan\n","stacked_barplot(data, 'housing', 'y')"]},{"cell_type":"markdown","source":["The number of yeses for people with no mortage of 1432 is close to 1464 for those paying mortgages. A closer examination however shows 8.97% of the no mortgage population said yes versus 6.1% among those with mortgages."],"metadata":{"id":"jBC77dIwhr3s"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ApfPZjTHVUsq"},"outputs":[],"source":["# target variable y vs has personal loan\n","stacked_barplot(data, 'loan', 'y')"]},{"cell_type":"markdown","source":["People with personal loans tend to say no at a higher rate compered to people without."],"metadata":{"id":"lpXb1ipYhS73"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"g6zItDyLVeWm"},"outputs":[],"source":["# target variable y vs contact type\n","stacked_barplot(data, 'contact', 'y')"]},{"cell_type":"markdown","source":["A larger proportion of contacts with cellular contact said yes than telephone both in actual quantity and in proportion ralative to sample size."],"metadata":{"id":"UFwmIqmMlCtO"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"la52PGe0VeSw"},"outputs":[],"source":["# target variable y vs last contact month\n","stacked_barplot(data, 'month', 'y')"]},{"cell_type":"markdown","source":["For calls made in October, 49 of 80 (63%) said yes, in March 125 of 258 (48%) said yes. With 791, May has the most yeses though this makes up about 6% success rate for May calls."],"metadata":{"id":"SIYmuDL4mhFp"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"HWH_bdzTVePD"},"outputs":[],"source":["# crosstab table to analyse education level vs job type\n","plt.figure(figsize=(15, 8))\n","sns.heatmap(pd.crosstab(data['education'], data['job']), annot=True, fmt='g', cmap='turbo',)\n","plt.title('Education vs Job')\n","plt.ylabel('Level of Education')\n","plt.xlabel('Type of Job')\n","plt.show()"]},{"cell_type":"markdown","source":["The management job category is dominated by people with tertiary education (6667) the most visible combination. People with secondary education tend to land jobs in the blue collar sector (5144), then technician (4788), then admin (3723)."],"metadata":{"id":"Tiq-6Ciww57m"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"tz8Fz2aSVeLa"},"outputs":[],"source":["# Compering credit default for House loans to Personal Loans by account balance\n","\n","plt.figure(figsize=(12, 6))\n","plt.subplot(1, 2, 1)\n","sns.barplot(data=data, y='housing', x='balance', hue='default', palette= 'autumn', ci=None)\n","plt.title('Bank Balance of Defaulter by Loan Type - Housing')\n","\n","plt.subplot(1, 2, 2)\n","sns.barplot(data=data, y='loan', x='balance', hue='default', palette='spring', ci=None)\n","plt.title('Bank Balance of Defaulter by Loan Type - Personal Loan')\n","plt.show()"]},{"cell_type":"markdown","source":["In all segments, people in the red (negative balances) have also defaulted on their credit. In the housing category, clients with no mortgages to pay have bigger account balances. In the category for personal loans, larger account balances also belong to the group with no loan."],"metadata":{"id":"mRzGVHYq0KSN"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"63zqMv65WBQq"},"outputs":[],"source":["# heatmap showing correlation between numerical variables\n","plt.figure(figsize=(12,7))\n","sns.heatmap(data[['age', 'balance', 'day', 'duration', 'campaign']].corr(), annot= True, vmin= -1, vmax= 1,fmt='.2f', cmap='BrBG')\n","plt.show()"]},{"cell_type":"markdown","source":["There is no strong correlation amoung numerical categories, which is a good thing for model building as the risk of multicollinearity is reduced."],"metadata":{"id":"uii-_7qD4mnY"}},{"cell_type":"code","source":["# correlation between target variable and numerical variables\n","sns.pairplot(data[['age', 'balance', 'day', 'duration', 'campaign', 'y']], hue= 'y')\n","plt.show()"],"metadata":{"id":"RhhDKhLBGwMD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["A few categories like `balance`, `duration` and `campaign` are showing linear relationships. The results show a similar pattern and distribution between `duration` and `campaign`. However, it would appear that duration has more yeses as time increases, while the increase in campaigns does not seem to necessarily increase yeses."],"metadata":{"id":"l48Z2kcFD2lt"}},{"cell_type":"markdown","metadata":{"id":"L8G2L807Vx2B"},"source":["## ðŸ› ï¸ Feature Engineering & Cleaning\n","\n","- Create derived features to enhance model learning:\n","  - `age_group` based on customer age.\n","  - `call_duration_category` based on call duration length.\n","  - `contact_frequency` to measure prior customer interaction history.\n","- Handle missing values, duplicates, outliers, and encode categorical variables."]},{"cell_type":"markdown","source":["Transforming our predictable variable to a numeric binary variable"],"metadata":{"id":"D9tdVB-XShaX"}},{"cell_type":"code","source":["# encode y-\"has client subscribed to term deposit\" where certifid; yes is 1, no is 0\n","data['y'] = data['y'].map({'yes': 1, 'no': 0})"],"metadata":{"id":"QXWkaPWbS5Gi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Checking for Duplicates, Missing Values & Outliers"],"metadata":{"id":"FygC3-0v_wk_"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"oajWMUJnVwvA"},"outputs":[],"source":["# Checking for duplicate values\n","print(f'There are {data.duplicated().sum()} duplicate rows in the dataset.')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7G6E-bn9X2Jr"},"outputs":[],"source":["# Checking for missing values in the data\n","print(f'There are {data.isna().sum().sum()} missing values in the dataset.')"]},{"cell_type":"code","source":["# Outlier detection using boxplot\n","original_num_cols = ['age', 'balance', 'day', 'duration', 'campaign']\n","\n","plt.figure(figsize=(12, 12))\n","\n","for i, variable in enumerate(original_num_cols):\n","    plt.subplot(3, 3, i + 1)\n","    plt.boxplot(data[variable], whis=1.5)\n","    plt.tight_layout()\n","    plt.title(variable)\n","plt.show()"],"metadata":{"id":"0HK4JEq1Dp7l"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- There are multiple outliers in the data.\n","- Outliers caused by extreem values randomly appearing in the data can throw models off-balance, whether they are there as real values or due to errors in data collection and collation.\n","- We will treat for some outliers.\n"],"metadata":{"id":"Ovn-OpsLANgM"}},{"cell_type":"code","source":["#    --- Treating Outliers ---\n","\n","# Cap duration at 25 mins\n","data['duration'] = data['duration'].clip(upper=1500)\n","\n","# Cap age between 18 and 75\n","data['age'] = data['age'].clip(lower=18, upper=75)\n","\n","# Cap campaign at 15\n","data['campaign'] = data['campaign'].clip(upper=15)\n","\n","# Winsorize balance ~  -3000 and 40000 range\n","lower, upper = np.percentile(data['balance'], [1, 99])\n","data['balance'] = data['balance'].clip(lower, upper)"],"metadata":{"id":"L97OmOx_HNo1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[" **Feature Engineering**\n","- Adding some extra columns with new categories can help unlock value and enrich our current data for effective outputs."],"metadata":{"id":"nd-1BRR6BMBY"}},{"cell_type":"code","source":["#      --- Creating new columns ---\n","\n","# Put 'age' into age group bins (18-30, 31-40, ..., 60+)\n","data['age_group'] = pd.cut(data['age'], bins=[0, 30, 40, 50, 60, float('inf')], labels=['18-30', '31-40', '41-50', '51-60', '60+'])\n","\n","# Create 'financial_burden' flag (1 if any of default/housing/loan is 'yes')\n","data['financial_burden'] = ((data['default'] == 'yes') | (data['housing'] == 'yes') | (data['loan'] == 'yes')).astype(int)\n","\n","# Categorize 'balance' into negative/low/high positive\n","data['balance_category'] = pd.cut(data['balance'],bins=[-float('inf'), 0, 1000, float('inf')],labels=['negative', 'low_positive', 'high_positive'])\n","\n","# Bin 'duration' into call duration categories (short/medium/long)\n","data['call_duration_category'] = pd.cut(data['duration'],bins=[0, 60, 180, float('inf')],labels=['short', 'medium', 'long'],include_lowest=True)\n","\n","# Combine 'housing' and 'loan' into 'total_loans' (0/1/2)\n","data['total_loans'] = data['housing'].map({'yes': 1, 'no': 0}) + data['loan'].map({'yes': 1, 'no': 0})\n","\n","# Create 'age_financial_burden' interaction (concatenates age_group and financial_burden)\n","data['age_financial_burden'] = (data['age_group'].astype(str) + '_' +\n","                                data['financial_burden'].map({0: 'no_burden', 1: 'has_burden'})).astype('category')\n","\n","# Create 'contact_frequency' flag (1 if contacted multiple times, 0 if once)\n","data['contact_frequency'] = (data.get('campaign', 1) > 1).astype(int)"],"metadata":{"id":"SS1lkXqoIOOI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### ðŸ“Š**EDA**\n","After some changes, it is only appropriate that we do some EDA again."],"metadata":{"id":"-cXkS7fBR0lz"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"uvib9NxHG_cu"},"outputs":[],"source":["# Analysing new columns\n","new_columns = ['age_group', 'financial_burden', 'balance_category', 'call_duration_category',\n","               'total_loans', 'age_financial_burden', 'contact_frequency' ]\n","for col in new_columns:\n","    print(data[col].value_counts())\n","    print('~' * 45)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v_FPCJPfdoKR"},"outputs":[],"source":["# Display the first few rows of the updated dataset\n","print(data.head())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_EUVTTsvF4oV"},"outputs":[],"source":["# Show data types after transformations\n","data.info()"]},{"cell_type":"code","source":["# Define categorical & numerical columns\n","\n","categorical_cols = [\n","    'job', 'marital', 'education', 'default', 'housing','loan', 'contact','month', 'age_group',\n","    'balance_category', 'call_duration_category', 'age_financial_burden', 'job_education_level'\n","]\n","\n","numerical_cols = [\n","    'age', 'balance', 'day', 'duration', 'campaign',\n","    'total_loans', 'financial_burden', 'contact_frequency'\n","]"],"metadata":{"id":"p2VsYb5op2WT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# target variable vs contact frequency\n","stacked_barplot(data, 'contact_frequency', 'y')"],"metadata":{"id":"PPz_nbmGFOPo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- Customers who have been contacted once (0) have a slightly better chance of subscribing than those contacted more then once (1). ~8% for once vs ~6% for more than once."],"metadata":{"id":"rlKEeY7ukVLK"}},{"cell_type":"code","source":["# target variable y vs call duration\n","stacked_barplot(data, 'call_duration_category', 'y')"],"metadata":{"id":"i22Gso4CyJXA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- This graphic comfirms the earlier deduction that the longer the call, the higher the chance of yes. But what is the most effective call length?"],"metadata":{"id":"sr4bXlifjwX3"}},{"cell_type":"code","source":["# target variable y vs age group\n","stacked_barplot(data, 'age_group', 'y')\n"],"metadata":{"id":"5L7-D1pryWrQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- Though its has the least people, the 60+ age group is the most willing group with almost 40% 'yes' conversion. The 18-30age group has just above 10% 'yes' rate. The least successful groups for yes are 41-50 and 51-60 groups with 6%."],"metadata":{"id":"dEw6CQHrg9u8"}},{"cell_type":"code","source":["# crosstab table to analyse age group vs balance category\n","plt.figure(figsize=(15, 8))\n","sns.heatmap(pd.crosstab(data['age_group'], data['balance_category']), annot=True, fmt='g', cmap='YlOrBr',)\n","plt.title('Age Group vs Balance Category')\n","plt.ylabel('Age Group')\n","plt.xlabel('Balance Category')\n","plt.show()"],"metadata":{"id":"1TY_PRv9HsKr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- Most people are in the low balance category which is consistant with the original mean for balance, this bracket is dominated by the 31 to 40 age group.\n","- The 60+ group has the least people across the balance categories."],"metadata":{"id":"h8Nvea4rfv0g"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"5dl-BP42hNrK"},"outputs":[],"source":["# Correlation heatmap inclusive of new numerical columns\n","numerical_cols = ['age', 'balance', 'day', 'duration', 'campaign', 'financial_burden', 'total_loans', 'contact_frequency']\n","corr_matrix = data[numerical_cols + ['y']].corr()\n","plt.figure(figsize=(14, 8))\n","sns.heatmap(corr_matrix, annot=True, vmin= -1, vmax= 1, fmt='.2f', cmap='seismic')\n","plt.title('Correlation Matrix After Feature Engineering')\n","plt.show()"]},{"cell_type":"markdown","source":["- We note the obvious correlation between `total_loans` and `financial_burden`.\n","- The target variable `y`, has the strongest correlation with duration among the numerical variables.\n","___"],"metadata":{"id":"2J5ageme9MS_"}},{"cell_type":"markdown","source":["## ðŸ§ª Pre-Call Modeling Workflow\n","\n","This phase focuses on identifying customers **unlikely** to subscribe â€” before any outreach is made.  \n","The goal is to **reduce resource wastage** by excluding low-probability customers early in the pipeline.\n","\n","We use only pre-contact attributes (demographics, financial data) and avoid any call-related metadata.  \n","The outcome is a cost-saving filter to help campaign managers focus on higher-potential leads.\n","\n","Below is a high-level diagram illustrating the two-phase modeling strategy:\n"],"metadata":{"id":"RUPoGryJs1Yr"}},{"cell_type":"markdown","source":["     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n","     â”‚                      â”‚          â”‚                      â”‚\n","     â”‚  Pre-Call Model      â”‚          â”‚  Post-Call Model     â”‚\n","     â”‚ (Predict \"No\")       â”‚          â”‚ (Predict \"Yes\")      â”‚\n","     â”‚                      â”‚          â”‚                      â”‚\n","     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n","               â”‚                                  â”‚\n","\n","\n","---\n","\n"],"metadata":{"id":"4Eclq5Yn3_xf"}},{"cell_type":"markdown","source":["**Pre-Call Preprocessing and Resampling (SMOTE + Undersampling)**\n","\n","This stage applies preprocessing and class balancing to prepare the training data for modeling.\n","\n","- **Preprocessing** includes median imputation and min-max scaling for numerical features, and one-hot encoding for categorical features.\n","- **SMOTE** is used to synthetically upsample the minority class to 60% of the majority.\n","- **Random undersampling** is then applied to trim the majority class to 80%, resulting in ~75% class balance overall.\n","\n","Both resampling and transformation steps are applied consistently via scikit-learn pipelines."],"metadata":{"id":"SiJogaZYUCM8"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Dbj1fYw9xtGY"},"outputs":[],"source":["# --- Preprocessing ---\n","\n","# define X and y\n","pre_call_features = [\n","    'age', 'balance', 'total_loans', 'job', 'marital', 'education',\n","    'default', 'housing', 'loan', 'age_group', 'balance_category'\n","]\n","X_pre = data[pre_call_features]\n","y_pre = data['y']\n","\n","# Split into Train (50%), Val (25%), Test (25%)\n","X_train_pre, X_temp_pre, y_train_pre, y_temp_pre = train_test_split(\n","    X_pre, y_pre, test_size=0.5, stratify=y_pre, random_state=seed\n",")\n","X_val_pre, X_test_pre, y_val_pre, y_test_pre = train_test_split(\n","    X_temp_pre, y_temp_pre, test_size=0.5, stratify=y_temp_pre, random_state=seed\n",")\n","\n","print(f\"Train: {X_train_pre.shape}, Val: {X_val_pre.shape}, Test: {X_test_pre.shape}\")\n","print('~' * 50)\n","print('Percentage of classes in training set:')\n","print(y_train_pre.value_counts(normalize=True))\n","print('~' * 50)\n","print('Percentage of classes in validation set:')\n","print(y_val_pre.value_counts(normalize=True))\n","print('~' * 50)\n","print('Percentage of classes in test set:')\n","print(y_test_pre.value_counts(normalize=True))\n","print('~' * 50)"]},{"cell_type":"markdown","source":["**Finalize Prepocessor, applying SMOTE only on the training data**"],"metadata":{"id":"xgw2jW81GDCJ"}},{"cell_type":"code","source":["# --- SMOTE + Undersampling Setup ---\n","\n","pre_call_preprocessor = ColumnTransformer(\n","    transformers=[\n","        ('num', Pipeline([\n","            ('imputer', SimpleImputer(strategy='median')),\n","            ('scaler', MinMaxScaler())\n","        ]), ['age', 'balance', 'total_loans']),\n","\n","        ('cat', Pipeline([\n","            ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n","            ('encoder', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'))\n","        ]), ['job', 'marital', 'education', 'default', 'housing', 'loan', 'age_group', 'balance_category'])\n","    ]\n",")\n","\n","# Preprocessing (fitted here)\n","X_train_pre_processed = pre_call_preprocessor.fit_transform(X_train_pre)\n","X_val_pre_processed = pre_call_preprocessor.transform(X_val_pre)\n","X_test_pre_processed = pre_call_preprocessor.transform(X_test_pre)\n","\n","# SMOTE + RandomUnderSampler (reference copy for reproducibility)\n","sm_pre_smote = SMOTE(sampling_strategy=0.6, random_state=seed)\n","under_pre = RandomUnderSampler(sampling_strategy=0.8, random_state=seed)\n","X_train_pre_smote, y_train_pre_smote = sm_pre_smote.fit_resample(X_train_pre_processed, y_train_pre)\n","X_train_pre_smote_under, y_train_pre_smote_under = under_pre.fit_resample(X_train_pre_smote, y_train_pre_smote)\n","\n","# Define classifiers to tune and compare\n","compnb_model = ComplementNB(alpha=0.01, fit_prior=True)\n","bernb_model = BernoulliNB(alpha=0.5, fit_prior=True)\n","\n","# Print distribution and note\n","print(\"\\033[1m Preprocessing & Resampling Summary:\\033[0m\")\n","print(\"- Numeric features: ['age', 'balance', 'total_loans'] (median-imputed & min-max scaled)\")\n","print(\"- Categorical features: ['job', 'marital', 'education', 'default', 'housing', 'loan', 'age_group', 'balance_category'] (OHE, drop='first')\")\n","print(\"- Applied SMOTE to 60% and undersampling to 80% -> Net ~75% minority balance\")\n","print('*' * 50)\n","print(\"Pre-Call Original Distribution:\")\n","print(y_train_pre.value_counts(normalize=True))\n","print('*' * 50)"],"metadata":{"id":"vov7pE-_rWvi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","### Pre-Call: Classifier Benchmarking\n","\n","We evaluate eight classifiers using default settings with pipelines on the original imbalanced training set:\n","- Logistic Regression, Random Forest, XGBoost, Gradient Boosting, SVC\n","- KNN, ComplementNB, BernoulliNB\n"],"metadata":{"id":"5dobPPUj1YbV"}},{"cell_type":"code","source":["# --- Model Benchmarking Setup ---\n","\n","benchmark_models = {\n","    'LogReg': LogisticRegression(C=1.0, penalty='l2', solver='lbfgs', max_iter=500, random_state=seed),\n","    'RF': RandomForestClassifier(n_estimators=100, max_depth=10, min_samples_split=5, min_samples_leaf=2, random_state=seed),\n","    'XGB': XGBClassifier(n_estimators=100, max_depth=5, learning_rate=0.1, subsample=0.8,\n","                         colsample_bytree=0.8, eval_metric='logloss', use_label_encoder=False, random_state=seed),\n","    'SVC': SVC(C=1.0, kernel='rbf', gamma='scale', probability=True, random_state=seed),\n","    'GBM': GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, subsample=0.8, random_state=seed),\n","    'BerNB': bernb_model,\n","    'CompNB': compnb_model,\n","    'KNN': KNeighborsClassifier(n_neighbors=5, weights='distance', metric='manhattan')\n","}\n","\n","benchmark_cv_results = {}\n","for name, model in benchmark_models.items():\n","    pipe = Pipeline([\n","        ('preprocessing', pre_call_preprocessor),\n","        ('classifier', model)\n","    ])\n","    # Define scoring and cv\n","    scoring = {\n","        'accuracy': make_scorer(accuracy_score),\n","        'precision': make_scorer(precision_score, pos_label=1, zero_division=0),\n","        'recall': make_scorer(recall_score, pos_label=1),\n","        'f1': make_scorer(f1_score, pos_label=1),\n","        'roc_auc': 'roc_auc',\n","        'average_precision': 'average_precision'\n","    }\n","    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n","    scores = cross_validate(pipe, X_train_pre, y_train_pre, scoring=scoring, cv=cv, n_jobs=-1)\n","    benchmark_cv_results[name] = {metric: round(scores[f'test_{metric}'].mean(), 4) for metric in scoring.keys()}\n","\n","benchmark_df = pd.DataFrame(benchmark_cv_results).T.sort_values('f1', ascending=False)\n","print(\"\\n Full 8-Model CV Benchmark:\")\n","display(benchmark_df)"],"metadata":{"id":"WZ84dAv5z-j8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["âœ… **Final Model Selection (CompNB vs BerNB)**\n","- After full 8-model benchmarking, tree-based models performed well on accuracy but struggled with recall.  \n","- Naive Bayes variants (especially ComplementNB) offered stronger F1 and recall, leading to the selection of two models for deeper evaluation.\n","- ComplementNB (CompNB) and BernoulliNB (BerNB) were selected for detailed threshold tuning.\n","\n","Key reasons for shortlisting:\n","- **CompNB** showed the highest recall and F1 score during 5-fold CV.\n","- **BerNB** had strong precision, offering a valuable contrast in the recallâ€“precision trade-off.\n","\n","ðŸ” *Note on Hyperparameter Tuning:*  \n","No hyperparameter tuning was applied at this stage because Naive Bayes classifiers like ComplementNB and BernoulliNB have limited tunable parameters and generally perform well with default configurations when combined with proper preprocessing. The goal here was to emphasize **simplicity, interpretability, and class-level performance**, which these models offered without additional complexity.\n","___"],"metadata":{"id":"EK-1KNFr6277"}},{"cell_type":"markdown","source":["### Pre-Call: Cross-Validation Evaluation\n","\n","Using 5-fold Stratified Cross-Validation, we compare the two selected classifiers (ComplementNB and BernoulliNB) on:\n","- Accuracy\n","- Precision\n","- Recall\n","- F1 Score\n","- ROC-AUC\n","- Average Precision\n","\n","Performance metrics are visualized to aid in final model decision-making.\n"],"metadata":{"id":"Xf3xMeKYMi2x"}},{"cell_type":"code","source":["# --- Cross-Validation Comparison (Top Classifiers) ---\n","\n","models = {\n","    'CompNB': compnb_model,\n","    'BerNB': bernb_model\n","}\n","\n","scoring = {\n","    'accuracy': make_scorer(accuracy_score),\n","    'precision': make_scorer(precision_score, pos_label=1, zero_division=0),\n","    'recall': make_scorer(recall_score, pos_label=1),\n","    'f1': make_scorer(f1_score, pos_label=1),\n","    'roc_auc': 'roc_auc',\n","    'average_precision': 'average_precision'\n","}\n","\n","cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n","cv_results_pre = {}\n","\n","for name, model in models.items():\n","    pipeline = Pipeline([\n","        ('preprocessing', pre_call_preprocessor),\n","        ('classifier', model)\n","    ])\n","    scores = cross_validate(\n","        pipeline, X_train_pre, y_train_pre,\n","        scoring=scoring, cv=cv, return_train_score=False, n_jobs=-1\n","    )\n","    cv_results_pre[name] = {metric: round(scores[f'test_{metric}'].mean(), 4) for metric in scoring.keys()}\n","\n","cv_df_pre = pd.DataFrame(cv_results_pre).T.sort_values('f1', ascending=False)\n","\n","# --- Plotting CV Metrics ---\n","fig, axs = plt.subplots(1, 3, figsize=(16, 5))\n","cv_df_pre.sort_values('recall', ascending=True)['recall'].plot(kind='barh', ax=axs[0], color='skyblue')\n","axs[0].set_title('Recall (Class 1)')\n","axs[0].set_xlabel('Recall Score')\n","cv_df_pre.sort_values('f1', ascending=True)['f1'].plot(kind='barh', ax=axs[1], color='orange')\n","axs[1].set_title('F1 Score')\n","axs[1].set_xlabel('F1 Score')\n","cv_df_pre.sort_values('precision', ascending=True)['precision'].plot(kind='barh', ax=axs[2], color='green')\n","axs[2].set_title('Precision')\n","axs[2].set_xlabel('Precision Score')\n","plt.suptitle('Pre-Call Model Performance (Cross-Validation)', fontsize=16)\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"lcFCHxEOHDV0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","### Pre-Call: Threshold Search & Tuning\n","\n","Default probability threshold (0.5) may not be optimal for business objectives focused on maximizing recall and F1.  \n","We systematically search alternative thresholds to find a better balance between True Positives and False Positives.\n","\n","Threshold vs metric performance is visualized to support final threshold selection"],"metadata":{"id":"tBtrD7A5M0__"}},{"cell_type":"code","source":["# --- Model Fitting for Threshold Tuning (Fixed) ---\n","\n","# Directly fit models on already preprocessed + resampled data (skip preprocessing here)\n","compnb_model.fit(X_train_pre_smote_under, y_train_pre_smote_under)\n","bernb_model.fit(X_train_pre_smote_under, y_train_pre_smote_under)\n","\n","# Now wrap these in simple probability-only pipelines for validation prediction\n","compnb_pipeline = Pipeline([\n","    ('classifier', compnb_model)\n","])\n","bernb_pipeline = Pipeline([\n","    ('classifier', bernb_model)\n","])\n","\n","# Predict probabilities on validation set (already preprocessed)\n","y_val_probs_compnb = compnb_model.predict_proba(X_val_pre_processed)[:, 1]\n","y_val_probs_bernb = bernb_model.predict_proba(X_val_pre_processed)[:, 1]\n","\n"],"metadata":{"id":"t-tw3acbHDRi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["ðŸ” **Threshold Tuning Summary (CompNB vs BerNB)**\n","\n","In this stage, both Complement Naive Bayes (CompNB) and Bernoulli Naive Bayes (BerNB) were evaluated across multiple thresholds (0.45 to 0.72) to identify optimal trade-offs between True Positives (TP) and False Negatives (FN).\n","\n","âœ… **Threshold 0.48 for CompNB** was selected as the balance point:\n","- It maintains **TP > FN**\n","- Delivers acceptable F1 (0.162) and Recall (0.581)\n","- Avoids overly sacrificing precision or accuracy\n","\n","This choice ensures we don't prematurely discard potential clients in the pre-call stage, aligning with business priorities while preserving model generalizability.\n"],"metadata":{"id":"7zl4fd-zbGFf"}},{"cell_type":"code","source":["# --- Threshold Tuning ---\n","\n","thresholds = np.arange(0.45, 0.75, 0.03)\n","tuning_metrics = []\n","\n","for t in thresholds:\n","    for name, probs, pipeline in [('CompNB', y_val_probs_compnb, compnb_pipeline),\n","                                  ('BerNB', y_val_probs_bernb, bernb_pipeline)]:\n","        y_pred = (probs >= t).astype(int)\n","        tn, fp, fn, tp = confusion_matrix(y_val_pre, y_pred).ravel()\n","        tuning_metrics.append({\n","            'Model': name,\n","            'Threshold': round(t, 2),\n","            'TP': tp, 'FP': fp, 'TN': tn, 'FN': fn,\n","            'Precision': round(precision_score(y_val_pre, y_pred, zero_division=0), 3),\n","            'Recall': round(recall_score(y_val_pre, y_pred), 3),\n","            'F1 Score': round(f1_score(y_val_pre, y_pred), 3),\n","            'Accuracy': round(accuracy_score(y_val_pre, y_pred), 3)\n","        })\n","\n","threshold_tuning_df = pd.DataFrame(tuning_metrics)\n","print(\"\\nThreshold Tuning Results (Validation Set):\")\n","display(threshold_tuning_df)\n"],"metadata":{"id":"Acvm-A7uO5M3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","### Pre-Call: Validation Confusion Matrix Analysis\n","- Analyze confusion matrix performance on validation folds.\n","- Focus on maximizing True Positives"],"metadata":{"id":"MhoIF_GHOJNQ"}},{"cell_type":"code","source":["# --- Confusion Matrix Heatmaps ---\n","\n","plt.figure(figsize=(12, 5))\n","for i, (name, probs) in enumerate([('CompNB', y_val_probs_compnb), ('BerNB', y_val_probs_bernb)]):\n","    y_pred = (probs >= 0.48).astype(int)\n","    cm = confusion_matrix(y_val_pre, y_pred)\n","    plt.subplot(1, 2, i+1)\n","    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False, square=True)\n","    plt.title(f'{name} Confusion Matrix @ Threshold 0.5')\n","    plt.xlabel('Predicted')\n","    plt.ylabel('Actual')\n","\n","plt.tight_layout()\n","plt.show()\n"],"metadata":{"id":"o5ab0uyPO489"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- **Left**: Complement Naive Bayes â€” captures more true negatives and true positives, favoring recall.\n","\n","- **Right**: Bernoulli Naive Bayes â€” higher overall accuracy, but misses more actual â€œnoâ€ clients (higher false negatives)."],"metadata":{"id":"iNZgdb_8B7TL"}},{"cell_type":"markdown","source":[" #### **Confusion Matrix Comparison â€” (Threshold = 0.48)**\n","\n","At this stage, we compare two models â€” **Complement Naive Bayes (CompNB)** and **Bernoulli Naive Bayes (BerNB)** â€” after adjusting the classification threshold to **0.48**. This threshold was chosen to improve the balance between true positives and false negatives for the \"no\" class.\n","\n","ðŸ” **Performance Summary**\n","\n","| Model   | Threshold | TP  | FP   | TN   | FN  | Precision | Recall | F1 Score | Accuracy |\n","|---------|-----------|-----|------|------|-----|-----------|--------|----------|----------|\n","| CompNB  | 0.480     | 421 | 4064 | 5212 | 303 | 0.094     | 0.581  | 0.162    | 0.563    |\n","| BerNB   | 0.480     | 342 | 2851 | 6425 | 382 | 0.107     | 0.472  | 0.175    | 0.677    |\n","\n","ðŸ§  **Interpretation**\n","\n","- **CompNB** achieves **higher recall (0.581)**, meaning it correctly identifies more of the actual \"no\" responders. However, it does so at the cost of precision and overall accuracy.\n","- **BerNB** offers **better precision (0.107)** and **higher overall accuracy (0.677)** but captures fewer true \"no\"s due to its lower recall (0.472).\n","\n","\n","âš–ï¸ **Trade-Offs**\n","\n","- While **accuracy** for BerNB exceeds **67%**, this metric is less informative in our **imbalanced pre-call context**, where \"no\" is the majority class.\n","- **Our objective is not high accuracy**, but rather:\n","  - **Minimizing false negatives** (people predicted as \"yes\" who are actually \"no\")\n","  - **Maximizing recall** for the \"no\" class to avoid wasted call efforts.\n","\n","Therefore, even though CompNB has **lower accuracy (56%)**, its **higher recall makes it more valuable** in this phase â€” helping to **exclude likely non-responders** more effectively.\n","\n","\n","\n"," âœ… **Decision**\n","\n","At this threshold, **CompNB is preferred** for pre-call exclusion, as it captures more â€œnoâ€ clients, aligning with our resource optimization goal.\n","\n"," ðŸ”— **Transition to Next Segment (Test Evaluation)**\n","Now that weâ€™ve validated our model performance using threshold tuning and confusion matrices on validation data, the next step is to evaluate the selected pre-call model (CompNB @ 0.48) on the unseen test set.\n","\n","---"],"metadata":{"id":"YXZJs9dT7cuQ"}},{"cell_type":"markdown","source":["### Pre-Call: Test Set Confusion Matrix Analysis\n","- Evaluate confusion matrix on holdout test set.\n","- Confirm model generalization performance.\n","- Confirm final model choice based on test scores."],"metadata":{"id":"Y61Nol2mcveY"}},{"cell_type":"code","source":["# --- Final Test Set Evaluation (Threshold = 0.48) ---\n","\n","optimal_threshold = 0.48\n","\n","# Predict probabilities on test set\n","y_test_probs_compnb = compnb_model.predict_proba(X_test_pre_processed)[:, 1]\n","y_test_probs_bernb = bernb_model.predict_proba(X_test_pre_processed)[:, 1]\n","\n","# Apply threshold\n","y_test_pred_compnb = (y_test_probs_compnb >= optimal_threshold).astype(int)\n","y_test_pred_bernb = (y_test_probs_bernb >= optimal_threshold).astype(int)\n","\n","# Compute metrics\n","def compute_test_metrics(y_true, y_pred, model_name):\n","    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n","    return {\n","        'Model': model_name,\n","        'TP': tp, 'FP': fp, 'TN': tn, 'FN': fn,\n","        'Precision': round(precision_score(y_true, y_pred, zero_division=0), 3),\n","        'Recall': round(recall_score(y_true, y_pred), 3),\n","        'F1 Score': round(f1_score(y_true, y_pred), 3),\n","        'Accuracy': round(accuracy_score(y_true, y_pred), 3)\n","    }\n","\n","test_metrics_compnb = compute_test_metrics(y_test_pre, y_test_pred_compnb, 'CompNB')\n","test_metrics_bernb = compute_test_metrics(y_test_pre, y_test_pred_bernb, 'BerNB')\n","\n","test_results_df = pd.DataFrame([test_metrics_compnb, test_metrics_bernb])\n","print(\"\\nFinal Test Set Metrics (Threshold = 0.48):\")\n","display(test_results_df)\n"],"metadata":{"id":"pi--sEM1AvQ2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# --- Test Set Confusion Matrix Heatmaps ---\n","\n","plt.figure(figsize=(12, 5))\n","for i, (name, y_pred) in enumerate([('CompNB', y_test_pred_compnb), ('BerNB', y_test_pred_bernb)]):\n","    cm = confusion_matrix(y_test_pre, y_pred)\n","    plt.subplot(1, 2, i+1)\n","    sns.heatmap(cm, annot=True, fmt='d', cmap='Greens', cbar=False, square=True)\n","    plt.title(f'{name} Confusion Matrix @ Threshold 0.48')\n","    plt.xlabel('Predicted')\n","    plt.ylabel('Actual')\n","\n","plt.tight_layout()\n","plt.show()\n"],"metadata":{"id":"7VeKqSakrSTn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Confusion Matrix Interpretation â€” Test Set (Threshold = 0.48)**\n","\n","Now that we've tuned our threshold and selected ComplementNB as our candidate model, we evaluate both **ComplementNB** and **BernoulliNB** on the **unseen test data** to assess generalization.\n","\n","\n","\n","ðŸ”¹ **ComplementNB â€” Test Confusion Matrix**\n","\n","|            | Predicted No | Predicted Yes |\n","|------------|--------------|----------------|\n","| **Actual No**  | **TN = 5230**   | **FP = 4046**      |\n","| **Actual Yes** | **FN = 296**     | **TP = 428**       |\n","\n","**Insights:**\n","- Captures **428 true positives**, indicating solid identification of potential subscribers.\n","- **296 false negatives**, meaning fewer â€œyesâ€ clients are missed â€” a strength for our use case.\n","- **4046 false positives** show the trade-off: some potential â€œyesâ€ clients are being filtered out.\n","\n","> âœ… Prioritizes **recall** â€” aligns with our pre-call objective of minimizing missed â€œnoâ€ clients.\n","\n","\n","\n","ðŸ”¹ **BernoulliNB â€” Test Confusion Matrix**\n","\n","|            | Predicted No | Predicted Yes |\n","|------------|--------------|----------------|\n","| **Actual No**  | **TN = 6401**   | **FP = 2875**       |\n","| **Actual Yes** | **FN = 380**    | **TP = 344**       |\n","\n","**Insights:**\n","- Higher **TN (6401)** and lower **FP (2875)** â€” more conservative in excluding customers.\n","- However, **TP = 344**, meaning fewer actual subscribers are caught.\n","- **380 false negatives** â€” more â€œyesâ€ clients are missed compared to CompNB.\n","\n","> âš ï¸ Prioritizes **precision and accuracy**, but at the cost of recall.\n","\n","\n","\n","ðŸ“Š **Performance Comparison Summary**\n","\n","| Metric        | ComplementNB | BernoulliNB |\n","|---------------|--------------|-------------|\n","| **True Positives**  | âœ… Higher (428) | Lower (344) |\n","| **False Negatives** | âœ… Lower (296)  | Higher (380) |\n","| **Precision**       | Lower         | âœ… Higher |\n","| **Recall**          | âœ… Higher     | Lower |\n","| **Accuracy**        | Lower         | âœ… Higher |\n","\n","\n","\n","âœ… **Final Verdict**\n","\n","Despite lower accuracy, **ComplementNB outperforms BernoulliNB in terms of recall**, which is **critical for the pre-call phase**. Our goal is to **correctly identify and exclude likely â€œnoâ€ clients**, and CompNB does that more effectively.\n","\n","> We will proceed with **ComplementNB @ threshold = 0.48** for final test evaluation and downstream recommendation.\n","\n","\n","---"],"metadata":{"id":"Ay8xeDBVpoSl"}},{"cell_type":"markdown","source":["\n","### Pre-Call: Time Efficiency Analysis of Final Model\n","- Show potential reduction in outbound call effort.\n","- Estimate operational savings based on True Positives captured."],"metadata":{"id":"3NdjFojVRPt8"}},{"cell_type":"code","source":["# --- Time Efficiency of ComplementNB Model ---\n","\n","# Final pre-call prediction for time saved calc\n","y_pred_pre = y_test_pred_compnb\n","\n","# Time saved using pre-call model\n","total_customers = len(y_test_pre)\n","predicted_no = sum(y_pred_pre == 0)\n","\n","# Simulate different call durations\n","call_durations = [3, 5, 10]  # in minutes\n","\n","print(\"ðŸ“ž Pre-Call Time Saved Simulation:\")\n","for minutes in call_durations:\n","    time_saved_hours = (predicted_no * minutes) / 60\n","    print(f\"- If each call = {minutes} min â†’ Time saved: {time_saved_hours:.2f} hours ({predicted_no} calls skipped)\")\n"],"metadata":{"id":"bwlXs2u8wZiN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def simulate_time_saved(y_true, y_pred, durations=[3, 5, 10]):\n","    skipped = sum(y_pred == 0)\n","    print(\"ðŸ“ž Time Saved Simulation:\")\n","    for m in durations:\n","        print(f\"- {m} min/call â†’ {(skipped * m)/60:.2f} hours saved ({skipped} calls skipped)\")\n","\n","simulate_time_saved(y_test_pre, y_test_pred_compnb)\n"],"metadata":{"id":"xkSyjTgOzv7a"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[" â±ï¸ **Time Efficiency from Pre-Call Model**\n","\n","The pre-call model was designed to filter out customers unlikely to subscribe, saving valuable time and resources before any contact is made.\n","\n","ðŸ“Š **Key Results:**\n","- **Calls skipped**: 5,526 customers predicted as unlikely to subscribe\n","- **Estimated time saved**:\n","  - â³ 3 mins/call â†’ **276.3 hours saved**\n","  - â³ 5 mins/call â†’ **460.5 hours saved**\n","  - â³ 10 mins/call â†’ **921.0 hours saved**\n","\n","ðŸ’¼ **Business Impact:**\n","- This model enables early filtering at scale, reducing agent workload and campaign costs.\n","- It is especially valuable in high-volume campaigns, allowing businesses to focus on customers with a higher chance of conversion.\n","- Time savings can now be redirected to **high-potential leads**, boosting overall ROI.\n","\n","---"],"metadata":{"id":"NHT9x-WOzHrI"}},{"cell_type":"markdown","source":["### Pre-Call: Traditional Segment Analysis\n","- Explore feature importance and segment tendencies among predicted \"No\" customers.\n","- Identify demographic or behavioral patterns (age group, financial burden)."],"metadata":{"id":"LLZRXNRatyby"}},{"cell_type":"code","source":["# --- Permutation Feature Importance (CompNB) ---\n","\n","# Fit permutation importance on test set\n","perm_importance = PermutationImportance(compnb_model, random_state=seed)\n","perm_importance.fit(X_test_pre_processed, y_test_pre)\n","\n","# Use names from fitted preprocessor\n","feature_names = pre_call_preprocessor.get_feature_names_out()\n","perm_df = pd.DataFrame({\n","    'Feature': feature_names,\n","    'Importance Mean': perm_importance.feature_importances_,\n","    'Importance Std': perm_importance.feature_importances_std_\n","}).sort_values('Importance Mean', ascending=False)\n","\n","print(\"\\nPermutation Feature Importances (CompNB):\")\n","display(perm_df.head(10))\n","\n","plt.figure(figsize=(10, 6))\n","sns.barplot(data=perm_df.head(10), y='Feature', x='Importance Mean')\n","plt.title('Top 10 Feature Importances (Permutation - CompNB)')\n","plt.xlabel('Mean Importance')\n","plt.ylabel('Feature')\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"9REBBrgSu2tt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Permutation Feature Importance â€“ Pre-Call Model (CompNB)**\n","\n","The pre-call model predicts customers unlikely to subscribe. Below are the most influential features (based on permutation importance) that help the model identify likely \"no\" responders:\n","\n","\n","ðŸ” **Top Predictive Features**\n","\n","| Feature                            | Importance | Interpretation |\n","|------------------------------------|------------|----------------|\n","| `job_student`                      | 0.005      | Students often declineâ€”likely due to lower financial engagement. |\n","| `age_group_60+`                    | 0.003      | Older clients (60+) frequently say \"no\", possibly due to retirement-related caution. |\n","| `age_group_51-60` / `41-50`        | ~0.002     | Middle-aged clients also contribute to non-subscription signals. |\n","| `balance_category_negative`        | 0.002      | Negative balances strongly correlate with non-subscription. |\n","| `balance` (numerical)              | 0.001      | Supports the above â€” low financial standing affects outcomes. |\n","\n","\n","ðŸ§­ **Strategic Implication**\n","\n","- These features **signal likely â€œnoâ€ responses**, guiding us to **deprioritize outreach** to:\n","  - **Students**\n","  - **Clients aged 60+**\n","  - **Clients with negative balances**\n","\n","\n","âš ï¸ **Note**\n","- These are **predictive**, not causal.\n","- They support more efficient targeting by flagging **less promising segments** before contact.\n","\n","---"],"metadata":{"id":"kuSwkEdYHuJU"}},{"cell_type":"markdown","source":["**Segment-Level Success Analysis (CompNB)**\n","\n","This analysis explores customer groups (by age and job-education segments) that had the highest rate of true positive predictions.\n","\n","- We look at **segments** where customers were predicted to subscribe and actually did.\n","- These insights support marketing targeting strategies and customer profiling.\n"],"metadata":{"id":"LUNXaG7pt5Hp"}},{"cell_type":"code","source":["# --- Segment Success Rate Analysis (Test Set) ---\n","\n","# Apply thresholded predictions to the test set\n","y_test_pred_opt = (y_test_probs_compnb >= optimal_threshold).astype(int)\n","\n","# Append predictions to the original test data\n","val_data_segmented = X_test_pre.copy()\n","val_data_segmented['y_true'] = y_test_pre.values\n","val_data_segmented['y_pred'] = y_test_pred_opt\n","\n","# Create composite segment: job + education\n","val_data_segmented['segment_combo'] = val_data_segmented['job'].astype(str) + ' | ' + val_data_segmented['education'].astype(str)\n","\n","# Get only true positives\n","true_positives = val_data_segmented[(val_data_segmented['y_true'] == 1) & (val_data_segmented['y_pred'] == 1)]\n","\n","# Segment success rate by age_group\n","segment_age = true_positives.groupby('age_group').size() / val_data_segmented.groupby('age_group').size()\n","segment_age = segment_age.sort_values(ascending=False).dropna().reset_index()\n","segment_age.columns = ['Segment', 'Success Rate']\n","segment_age['Category'] = 'Age Group'\n","\n","# Segment success rate by job + education\n","segment_combo = true_positives.groupby('segment_combo').size() / val_data_segmented.groupby('segment_combo').size()\n","segment_combo = segment_combo.sort_values(ascending=False).dropna().reset_index()\n","segment_combo.columns = ['Segment', 'Success Rate']\n","segment_combo['Category'] = 'Job | Education'\n","\n","# Combine segments\n","combined_segments = pd.concat([segment_age, segment_combo], ignore_index=True)\n","\n","# Display top segments\n","print(\"\\nCombined Segment Success Rates (Test Set):\")\n","display(combined_segments.head(10))\n","\n","# Plot top 10\n","plt.figure(figsize=(10, 6))\n","sns.barplot(\n","    data=combined_segments.head(10),\n","    y='Segment',\n","    x='Success Rate',\n","    hue='Category',\n","    dodge=False\n",")\n","plt.title('Top Segments by True Positive Success Rate (Test Set)')\n","plt.xlabel('Success Rate')\n","plt.ylabel('Segment')\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"cQEsAUJ9cNsS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Segment-Level Success Rate Analysis â€“ Post-Call Model**\n","\n","To complement feature importance, we examine **segment-level performance** to identify which customer groups the model **correctly predicts as subscribers (true positives)**.\n","\n","This helps answer:\n","> **â€œWhich groups are actually saying yes, and worth targeting?â€**\n","\n","\n","\n","ðŸŽ¯ **Key Segments with High True Positive Rates**\n","\n","| Segment                        | Success Rate | Category         |\n","|--------------------------------|--------------|------------------|\n","| `unknown | unknown`            | 0.200        | Job | Education  |\n","| `retired | tertiary`           | 0.191        | Job | Education  |\n","| `student | tertiary`           | 0.189        | Job | Education  |\n","| `blue-collar | tertiary`       | 0.152        | Job | Education  |\n","| `student | secondary`         | 0.149        | Job | Education  |\n","| `unknown | secondary`         | 0.125        | Job | Education  |\n","| `services | unknown`           | 0.107        | Job | Education  |\n","| `unemployed | primary`         | 0.100        | Job | Education  |\n","| `unknown | primary`            | 0.100        | Job | Education  |\n","| `student | unknown`            | 0.100        | Job | Education  |\n","\n","\n","\n","ðŸ§  **Interpretation**\n","\n","- Segments like **`retired | tertiary`**, **`student | tertiary`**, and **`blue-collar | tertiary`** show **strong post-call conversion potential**.\n","- Even **â€œunknownâ€ job/education** combinations show surprising conversion value â€” possibly due to underreported but engaged users.\n","- These insights can guide **refined targeting**, **personalized messaging**, or **prioritized follow-up**.\n","\n","\n","\n","ðŸ“Œ **Strategic Insight**\n","\n","Focus future call efforts on segments with **historically higher true positive rates** â€” especially those combining **education level** and **student/retired/blue-collar** jobs.\n","\n","---"],"metadata":{"id":"IbD-bm6ZIWhP"}},{"cell_type":"markdown","source":["### Pre-Call: Segment Profiling & Clustering Insights (Optional)\n","- If additional clustering applied, summarize profiles here.\n","- Deep dive into customer sub-segments if needed."],"metadata":{"id":"DQY9QNjZDyq3"}},{"cell_type":"code","source":["# --- Hierarchical Clustering on Pre-Call Data ---\n","\n","\n","# âœ… 1. Use already preprocessed training data (X_train_pre_processed)\n","# No re-scaling needed\n","\n","# âœ… 2. Optional Dimensionality Reduction via PCA (for dendrogram clarity)\n","pca = PCA(n_components=10, random_state=seed)\n","X_pca_pre = pca.fit_transform(X_train_pre_processed)\n","\n","# âœ… 3. Compute linkage matrix\n","Z_pre = linkage(X_pca_pre, method='ward')\n","\n","# âœ… 4. Plot dendrogram\n","plt.figure(figsize=(12, 6))\n","plt.title(\"ðŸ” Dendrogram - Pre-Call Clustering (Train Set)\")\n","dendrogram(Z_pre, truncate_mode='level', p=5)  # Show top 5 levels\n","plt.xlabel(\"Sample Index\")\n","plt.ylabel(\"Cluster Distance\")\n","plt.tight_layout()\n","plt.grid(True)\n","plt.show()\n","\n","# âœ… 5. Assign clusters (e.g., 4 clusters)\n","clusters_pre = fcluster(Z_pre, t=4, criterion='maxclust')\n","\n","# Add back cluster labels to original (X_train_pre) DataFrame for profiling\n","X_train_pre_clustered = X_train_pre.copy()\n","X_train_pre_clustered['cluster'] = clusters_pre\n","X_train_pre_clustered['y'] = y_train_pre.values  # Reattach target\n","\n","# âœ… 6. Cluster-wise Subscription Rates\n","cluster_summary = X_train_pre_clustered.groupby('cluster')['y'].value_counts(normalize=True).unstack().fillna(0)\n","print(\"\\nPre-Call Cluster Subscription Rates (%):\")\n","print((cluster_summary * 100).round(2))\n","\n","# Optional: Heatmap for visual effect\n","sns.heatmap((cluster_summary * 100).round(2), annot=True, fmt=\".2f\", cmap=\"YlGnBu\")\n","plt.title(\"Pre-Call Cluster-wise Subscription Distribution (%)\")\n","plt.ylabel(\"Cluster\")\n","plt.xlabel(\"Subscription Outcome\")\n","plt.show()\n"],"metadata":{"id":"tM6j6Xp21nuo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Numeric Feature Averages per Cluster\n","X_train_pre_clustered.groupby('cluster')[['age', 'balance', 'total_loans']].mean().round(2)\n"],"metadata":{"id":"iAMJL6Kg6sW1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Categorical Breakdown Example â€“ Job Distribution\n","X_train_pre_clustered.groupby('cluster')['job'].value_counts(normalize=True).unstack().fillna(0).round(2)\n"],"metadata":{"id":"iMQpSnSQ64rU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["####ðŸ”**Pre-Call Clustering & Segment Profiles**\n","\n","\n","ðŸŒ¿ **Cluster Subscription Outcomes**\n","\n","| Cluster | % No | % Yes | Notes |\n","|---------|------|--------|-------|\n","| **1**   | 90.77% | 9.23%  | Moderately high rejection group |\n","| **2**   | 91.82% | 8.18%  | Blue-collar skew; lower balance |\n","| **3**   | 92.57% | 7.43%  | Older cluster; retired & self-employed |\n","| **4**   | 94.52% | 5.48%  | Most resistant group; heavy blue-collar presence |\n","\n","\n","ðŸ“Š **Cluster Characteristics**\n","\n","#### Cluster 1\n","- **Avg Age**: 36.6\n","- **Avg Balance**: 1473\n","- **Top Jobs**: Management (55%), Technician (18%)\n","- **Loans**: Low (0.61 avg)\n","- **Takeaway**: Younger, professional group with high rejection but moderate potential.\n","\n","#### Cluster 2\n","- **Avg Age**: 33.4\n","- **Avg Balance**: 901\n","- **Top Jobs**: Blue-collar (31%), Technician (24%), Admin (18%)\n","- **Loans**: Moderate (0.87)\n","- **Takeaway**: Low balance, blue-collar segment. Low response â€” potential exclusion zone.\n","\n","#### Cluster 3\n","- **Avg Age**: 53.9\n","- **Avg Balance**: 1458\n","- **Top Jobs**: Management (21%), Retired (19%), Technician (15%)\n","- **Loans**: Low (0.57)\n","- **Takeaway**: Older segment; moderate wealth but low conversion. Possibly disengaged.\n","\n","#### Cluster 4\n","- **Avg Age**: 40.6\n","- **Avg Balance**: 1057\n","- **Top Jobs**: Blue-collar (41%), Technician (15%), Services (12%)\n","- **Loans**: Highest (0.92)\n","- **Takeaway**: Most resistant to term deposits. Strong exclusion candidate.\n","\n","\n","ðŸ“Œ **Recommendation**\n","- Prioritize **Cluster 1** if targeting any pre-call segment.\n","- Consider excluding **Clusters 3 & 4** to reduce contact effort and resource waste.\n","- Use this clustering alongside existing segment filters (e.g., `age_group`, `balance_category`) to refine campaign rules.\n","\n","---\n"],"metadata":{"id":"KP-8gxCV7OFh"}},{"cell_type":"markdown","source":["### Pre-Call: Final Round-Up\n","- Summarize Pre-Call model role, performance, and business impact.\n","- Recommendations for exclusion strategy and operational deployment.\n","\n","#### ðŸ“Œ Final Model: Complement Naive Bayes (ComplementNB)\n","- **Threshold Tuned**: 0.48\n","- **True Positives**: 428\n","- **Recall**: 59.1%\n","- **F1 Score**: 0.165\n","- **Accuracy**: 56.6%\n","\n","#### âš™ï¸ Methodology\n","- Used **only non-call features** (demographics, financial standing).\n","- Balanced the dataset using **SMOTE + RandomUnderSampler** to counteract heavy class imbalance (~75% majority class).\n","- Evaluated using 5-fold cross-validation, with a focus on **early elimination of non-responders**.\n","\n","#### âš™ï¸ Pre-Call Strategic Role\n","- **Early-stage filter** to remove low-likelihood prospects from the call queue.\n","- Helps reduce unnecessary call volume and focus agent efforts on higher-yield opportunities.\n","\n","#### ðŸ§  Key Insights\n","- Customers aged **60+**, and **students with tertiary education**, were most accurately predicted as non-subscribers.\n","- These segments may be **deprioritized** or approached with **alternative products**.\n","\n","ðŸŽ¯ **Outcome**\n","- While performance was modest, the model served its purpose as a **resource-saving filter**.\n","- Strong complement to the post-call model â€” together, they form a **two-tiered targeting pipeline**.\n","\n","---\n","---"],"metadata":{"id":"Fnwkfa5McEE8"}},{"cell_type":"markdown","metadata":{"id":"Qf5LJpXfITix"},"source":["## ðŸ“ž Post-Call Modeling Workflow\n","\n","This phase focuses on predicting whether a customer will subscribe **after a call has occurred**.  \n","We now include call metadata â€” such as duration, contact method, and campaign frequency â€” alongside customer demographics.\n","\n","The goal here is to **maximize conversion** by identifying high-probability responders.  \n","This model serves as a powerful follow-up targeting tool, helping agents and marketers focus efforts on leads most likely to convert.\n","\n","___"]},{"cell_type":"markdown","source":["### Post-Call: Feature Set Definition & Preprocessing\n","\n","- Define call-related and demographic features for modeling.\n","- Build preprocessing pipeline:\n","  - KNN imputation for numericals,\n","  - Mode imputation + OneHotEncoding for categoricals.\n","- Apply ADASYN to balance classes."],"metadata":{"id":"5gGcM_0pxiya"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"bKjvokPZI1G2"},"outputs":[],"source":["# --- Define Call-Related Features (Post-Call) ---\n","\n","call_related_features = ['duration', 'day', 'contact', 'month', 'campaign', 'call_duration_category', 'contact_frequency']\n","\n"," # Demographic and financial features to enhance modeling\n","additional_features = ['age', 'job', 'marital', 'education', 'default','housing', 'loan', 'age_group','balance',\n","                       'total_loans', 'age_financial_burden']\n","\n","# Define numerical and categorical features explicitly\n","numerical_features = ['age', 'balance', 'duration', 'day', 'campaign', 'total_loans', 'contact_frequency']\n","categorical_features = ['job', 'marital', 'education', 'default', 'housing','loan', 'contact',\n","                        'month', 'age_group', 'call_duration_category', 'age_financial_burden']\n","# Final post-call features\n","final_features = call_related_features + additional_features\n","X_post = data[final_features]\n","y_post = data['y']\n","\n","# Train-Test Split for Post-Call\n","X_train_post, X_temp_post, y_train_post, y_temp_post = train_test_split(\n","    X_post, y_post, test_size=0.5, random_state=seed, stratify=y_post)\n","\n","X_val_post, X_test_post, y_val_post, y_test_post = train_test_split(\n","    X_temp_post, y_temp_post, test_size=0.5, random_state=seed, stratify=y_temp_post)\n","\n","print(f\"Train: {X_train_post.shape}, Val: {X_val_post.shape}, Test: {X_test_post.shape}\")\n","print('~' * 50)\n","print('Percentage of classes in training set:')\n","print(y_train_post.value_counts(normalize=True))\n","print('~' * 50)\n","print('Percentage of classes in validation set:')\n","print(y_val_post.value_counts(normalize=True))\n","print('~' * 50)\n","print('Percentage of classes in test set:')\n","print(y_test_post.value_counts(normalize=True))\n","print('~' * 50)"]},{"cell_type":"markdown","source":["**Preprocessing + ADASYN Balancing (Post-Call)**\n","\n","This stage prepares the data and addresses class imbalance using the following steps:\n","\n","- **Preprocessing Pipeline**\n","  - *Numerical features* (`age`, `balance`, `total_loans`) are median-imputed and scaled using MinMaxScaler.\n","  - *Categorical features* are one-hot encoded after handling missing values with constant imputation.\n","\n","- **Balancing Strategy**\n","  - We apply **ADASYN (Adaptive Synthetic Sampling)** to improve minority class representation post-call, allowing the model to learn more nuanced signals from positive responders.\n","\n","This setup ensures the training data is both clean and balanced before model comparison and optimization begins.\n"],"metadata":{"id":"p9VNI2O78q8U"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"wfQOj-FWkKKq"},"outputs":[],"source":["# --- Preprocessing + ADASYN Balancing (Post-Call) ---\n","\n","post_call_preprocessor = ColumnTransformer(\n","    transformers=[\n","        ('num', Pipeline([\n","            ('imputer', KNNImputer(n_neighbors=5)),\n","            ('scaler', RobustScaler())\n","        ]), ['age', 'balance', 'duration', 'day', 'campaign', 'total_loans','contact_frequency']),\n","        ('cat', Pipeline([\n","            ('imputer', SimpleImputer(strategy='most_frequent')),  # Use mode imputation for categorical\n","            ('encoder', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'))\n","        ]), ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact','month',\n","             'age_group', 'call_duration_category', 'age_financial_burden'])\n","    ]\n",")\n","\n","\n","# Post-call processing\n","X_train_post_processed = post_call_preprocessor.fit_transform(X_train_post)\n","X_val_post_processed = post_call_preprocessor.transform(X_val_post)\n","X_test_post_processed = post_call_preprocessor.transform(X_test_post)\n","\n","# Switch to ADASYN instead SMOTE+Undersampling\n","sm_post_adasyn = ADASYN(sampling_strategy=0.25, random_state=seed)\n","X_train_post_adasyn, y_train_post_adasyn = sm_post_adasyn.fit_resample(X_train_post_processed, y_train_post)\n","\n","# Check ADASYN distribution\n","print(\"\\nPost-Call ADASYN Distribution:\")\n","print(pd.Series(y_train_post_adasyn).value_counts(normalize=True))\n","print('*' * 50)\n","print(\"Post-Call Original Distribution:\")\n","print(y_train_post.value_counts(normalize=True))\n","print('*' * 50)\n"]},{"cell_type":"markdown","source":["### Post-Call: Initial Model Benchmarking\n","\n","- Evaluate initial models:\n","  - Random Forest, Gradient Boosting, XGBoost, (others if tested).\n","- Focus on cross-validation metrics (F1, recall, precision).\n","- Select top candidate models based on CV results.\n"],"metadata":{"id":"yPgu6cZbFHP-"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"bEqSoehNmdds"},"outputs":[],"source":["# --- Multi-Model Benchmarking with 5-Fold CV ---\n","\n","# Toggle: True = safe tuned defaults, False = raw models\n","use_safe_defaults = True\n","\n","if use_safe_defaults:\n","    models = {\n","        'LogReg': LogisticRegression(C=1.0, penalty='l2', solver='lbfgs', max_iter=500, random_state=seed),\n","        'DTree': DecisionTreeClassifier(max_depth=5, min_samples_split=5, min_samples_leaf=2, random_state=seed),\n","        'RF': RandomForestClassifier(n_estimators=100, max_depth=10, min_samples_split=5, min_samples_leaf=2, bootstrap=True, random_state=seed),\n","        'XGB': XGBClassifier(n_estimators=100, max_depth=5, learning_rate=0.1, subsample=0.8, colsample_bytree=0.8, eval_metric='logloss', use_label_encoder=False, random_state=seed),\n","        'SVC': SVC(C=1.0, kernel='rbf', gamma='scale', probability=True, random_state=seed),\n","        'GBM': GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, subsample=0.8, random_state=seed),\n","        'BerNB': BernoulliNB(alpha=0.5, fit_prior=True),\n","        'KNN': KNeighborsClassifier(n_neighbors=5, weights='distance', metric='manhattan')\n","    }\n","else:\n","    models = {\n","        'LogReg': LogisticRegression(random_state=seed),\n","        'DTree': DecisionTreeClassifier(random_state=seed),\n","        'RF': RandomForestClassifier(random_state=seed),\n","        'XGB': XGBClassifier(eval_metric='logloss', use_label_encoder=False, random_state=seed),\n","        'SVC': SVC(probability=True, random_state=seed),\n","        'GBM': GradientBoostingClassifier(random_state=seed),\n","        'BerNB': BernoulliNB(),\n","        'KNN': KNeighborsClassifier()\n","    }\n","\n","# Define scoring metrics\n","scoring = {\n","    'accuracy': make_scorer(accuracy_score),\n","    'precision': make_scorer(precision_score, pos_label=1, zero_division=0),\n","    'recall': make_scorer(recall_score, pos_label=1),\n","    'f1': make_scorer(f1_score, pos_label=1),\n","    'roc_auc': 'roc_auc',\n","    'average_precision': 'average_precision'\n","}\n","\n","# Cross-validation setup\n","cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n","cv_results = {}\n","\n","# Run CV on each model\n","for name, model in models.items():\n","    pipeline = Pipeline([\n","        ('preprocessing', post_call_preprocessor),\n","        ('classifier', model)\n","    ])\n","    scores = cross_validate(\n","        pipeline, X_train_post, y_train_post,\n","        scoring=scoring, cv=cv, return_train_score=False\n","    )\n","    cv_results[name] = {\n","        metric: round(scores[f'test_{metric}'].mean(), 4) for metric in scoring.keys()\n","    }\n","\n","# Results DataFrame\n","cv_df = pd.DataFrame(cv_results).T.sort_values('f1', ascending=False)\n","print(\"\\nPost-Call CV Results (Class 1):\")\n","display(cv_df)\n","\n","# Model Selection Justification\n","print(\"\\nModels Selected for Tuning:\")\n","print(\"XGBoost (XGB) and Gradient Boosting (GBM) achieved the highest F1 scores and will proceed for final optimization.\")\n","\n","# Combined plots: F1, Recall+PR AUC, ROC AUC\n","fig, axs = plt.subplots(1, 3, figsize=(18, 5))\n","\n","# F1\n","cv_df[['f1']].sort_values('f1').plot(kind='barh', ax=axs[0], legend=False, color='darkorange')\n","axs[0].set_title('F1 Score by Model')\n","axs[0].set_xlabel('F1 Score')\n","\n","# Recall vs PR AUC\n","cv_df[['recall', 'average_precision']].sort_values('recall').plot(kind='barh', ax=axs[1])\n","axs[1].set_title('Recall vs PR AUC')\n","axs[1].set_xlabel('Score')\n","axs[1].legend(loc='lower right')\n","\n","# ROC AUC\n","cv_df[['roc_auc']].sort_values('roc_auc').plot(kind='barh', ax=axs[2], legend=False, color='seagreen')\n","axs[2].set_title('ROC AUC by Model')\n","axs[2].set_xlabel('ROC AUC')\n","\n","plt.suptitle('Model Performance (5-Fold CV)', fontsize=16)\n","plt.tight_layout()\n","plt.show()\n"]},{"cell_type":"markdown","source":["âœ… Outcome:\n","- **XGBoost (XGB)** and **Gradient Boosting (GBM)** achieved the highest F1 scores.\n","- These two models will proceed to hyperparameter tuning, threshold optimization and test set evaluation.\n","___"],"metadata":{"id":"M6jngx4VR1mP"}},{"cell_type":"markdown","source":["### Post-Call: Hyperparameter Tuning of Selected Models\n","\n","- Perform GridSearchCV or manual tuning on best candidates.\n","- Optimize key parameters (learning rate, max depth, etc.).\n","- Evaluate tuning impact on cross-validation scores.\n"],"metadata":{"id":"mMI5siQcOrOd"}},{"cell_type":"code","source":["# --- Final Tuning and Evaluation of Top Models ---\n","\n","\"\"\"\n","This block performs hyperparameter tuning for the top two models identified in Block 3: XGBoost and Gradient Boosting.\n","The goal is to further improve F1 performance while maintaining high accuracy and ROC AUC.\n","\"\"\"\n","\n","# Define F1 scorer\n","scorer = make_scorer(f1_score, pos_label=1)\n","\n","# CV strategy\n","cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n","\n","# ----------------------------\n","# XGBoost Tuning\n","# ----------------------------\n","xgb1 = XGBClassifier(random_state=seed, eval_metric='logloss', use_label_encoder=False)\n","\n","xgb1_params = {\n","    'n_estimators': [50, 100],\n","    'max_depth': [3, 6],\n","    'learning_rate': [0.01, 0.1],\n","    'scale_pos_weight': [9, 13]  # Adjusted for class imbalance\n","}\n","\n","xgb1_pipeline = Pipeline([\n","    ('preprocessing', post_call_preprocessor),\n","    ('classifier', xgb1)\n","])\n","\n","grid_xgb1 = GridSearchCV(\n","    xgb1_pipeline,\n","    {'classifier__' + k: v for k, v in xgb1_params.items()},\n","    scoring=scorer,\n","    cv=cv,\n","    n_jobs=-1\n",")\n","\n","grid_xgb1.fit(X_train_post, y_train_post)\n","print(\"Best XGB Parameters:\", grid_xgb1.best_params_)\n","\n","# Final XGB Model (fit on ADASYN-balanced data)\n","best_xgb1 = XGBClassifier(\n","    **{k.replace('classifier__', ''): v for k, v in grid_xgb1.best_params_.items()},\n","    random_state=seed, eval_metric='logloss', use_label_encoder=False\n",")\n","best_xgb1.fit(X_train_post_adasyn, y_train_post_adasyn)\n","\n","# ----------------------------\n","# Gradient Boosting Tuning\n","# ----------------------------\n","gbm1 = GradientBoostingClassifier(random_state=seed)\n","\n","gbm1_params = {\n","    'n_estimators': [100, 200],\n","    'max_features': [0.5, 0.7, 1.0],\n","    'learning_rate': [0.01, 0.1]\n","}\n","\n","gbm1_pipeline = Pipeline([\n","    ('preprocessing', post_call_preprocessor),\n","    ('classifier', gbm1)\n","])\n","\n","grid_gbm1 = GridSearchCV(\n","    gbm1_pipeline,\n","    {'classifier__' + k: v for k, v in gbm1_params.items()},\n","    scoring=scorer,\n","    cv=cv,\n","    n_jobs=-1\n",")\n","\n","grid_gbm1.fit(X_train_post, y_train_post)\n","print(\"Best GBM Parameters:\", grid_gbm1.best_params_)\n","\n","# Final GBM Model (fit on ADASYN-balanced data)\n","best_gbm1 = GradientBoostingClassifier(\n","    **{k.replace('classifier__', ''): v for k, v in grid_gbm1.best_params_.items()},\n","    random_state=seed\n",")\n","best_gbm1.fit(X_train_post_adasyn, y_train_post_adasyn)\n"],"metadata":{"id":"M-DbSQTnAZ_e"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["ðŸŽ¯ Tuned Hyperparameters:\n","- **XGB:** {'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100, 'scale_pos_weight': 9}\n","- **GBM:** {'learning_rate': 0.1, 'max_features': 0.5, 'n_estimators': 200}\n","---"],"metadata":{"id":"_PzzWWYcRAry"}},{"cell_type":"markdown","source":["### Post-Call: Threshold Search & Tuning\n","\n","- Search for optimal probability threshold.\n","- Aim to maximize F1 score and recall.\n","- Visualize threshold vs performance curves."],"metadata":{"id":"7_v-bxp5Hmgr"}},{"cell_type":"code","source":["# --- Threshold Tuning on Validation Set (Post-Call) ---\n","\n","thresholds = np.arange(0.50, 0.71, 0.03)\n","\n","# Store results\n","threshold_results = []\n","\n","# Get probabilities\n","y_val_probs_xgb = best_xgb1.predict_proba(X_val_post_processed)[:, 1]\n","y_val_probs_gbm = best_gbm1.predict_proba(X_val_post_processed)[:, 1]\n","\n","for thresh in thresholds:\n","    for model_name, y_probs in zip(['XGB', 'GBM'], [y_val_probs_xgb, y_val_probs_gbm]):\n","        y_pred_thresh = (y_probs >= thresh).astype(int)\n","\n","        TP = np.sum((y_val_post == 1) & (y_pred_thresh == 1))\n","        FP = np.sum((y_val_post == 0) & (y_pred_thresh == 1))\n","        TN = np.sum((y_val_post == 0) & (y_pred_thresh == 0))\n","        FN = np.sum((y_val_post == 1) & (y_pred_thresh == 0))\n","\n","        precision = precision_score(y_val_post, y_pred_thresh, zero_division=0)\n","        recall = recall_score(y_val_post, y_pred_thresh)\n","        f1 = f1_score(y_val_post, y_pred_thresh)\n","        accuracy = accuracy_score(y_val_post, y_pred_thresh)\n","\n","        threshold_results.append({\n","            'Model': model_name,\n","            'Threshold': round(thresh, 2),\n","            'TP': TP, 'FP': FP, 'TN': TN, 'FN': FN,\n","            'Precision': round(precision, 3),\n","            'Recall': round(recall, 3),\n","            'F1 Score': round(f1, 3),\n","            'Accuracy': round(accuracy, 3)\n","        })\n","\n","# Convert to DataFrame\n","threshold_df = pd.DataFrame(threshold_results)\n","\n","# Show top 10 rows sorted by F1\n","print(\"\\n Threshold Tuning Results (Validation Set):\")\n","display(threshold_df.sort_values(by=['Model', 'F1 Score'], ascending=[True, False]).groupby('Model').head(5))\n","\n","# Plot F1 trends\n","plt.figure(figsize=(10, 5))\n","sns.lineplot(data=threshold_df, x='Threshold', y='F1 Score', hue='Model', marker='o')\n","plt.title('F1 Score Across Thresholds (Validation Set)')\n","plt.ylabel('F1 Score')\n","plt.xlabel('Threshold')\n","plt.grid(True)\n","plt.tight_layout()\n","plt.show()\n"],"metadata":{"id":"miQknP17Hlzt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Post-Call: Test Set Evaluation & Confusion Matrix\n","\n","- Evaluate tuned model on the test set.\n","- Display confusion matrix for final performance check.\n","- Confirm final model choice (likely XGBoost tuned with threshold)."],"metadata":{"id":"hsg3m9DgKXa9"}},{"cell_type":"code","source":["# --- Evaluation on Test Set (Post-Call) ---\n","\n","# Apply optimal thresholds\n","xgb_threshold = 0.68\n","xgb_test_probs = best_xgb1.predict_proba(X_test_post_processed)[:, 1]\n","y_test_pred_xgb = (xgb_test_probs >= xgb_threshold).astype(int)\n","\n","gbm_threshold = 0.50\n","gbm_test_probs = best_gbm1.predict_proba(X_test_post_processed)[:, 1]\n","y_test_pred_gbm = (gbm_test_probs >= gbm_threshold).astype(int)\n","\n","# Compute confusion matrices\n","def confusion_metrics(y_true, y_pred):\n","    cm = confusion_matrix(y_true, y_pred)\n","    tn, fp, fn, tp = cm.ravel()\n","    return {\n","        'TP': tp,\n","        'FP': fp,\n","        'TN': tn,\n","        'FN': fn,\n","        'Precision': round(precision_score(y_true, y_pred, zero_division=0), 3),\n","        'Recall': round(recall_score(y_true, y_pred), 3),\n","        'F1 Score': round(f1_score(y_true, y_pred), 3),\n","        'Accuracy': round(accuracy_score(y_true, y_pred), 3)\n","    }\n","\n","xgb_test_results = confusion_metrics(y_test_post, y_test_pred_xgb)\n","gbm_test_results = confusion_metrics(y_test_post, y_test_pred_gbm)\n","\n","# Build comparison table\n","final_test_df = pd.DataFrame([xgb_test_results, gbm_test_results], index=['XGB (0.68)', 'GBM (0.50)'])\n","print(\"\\nFinal Test Set Metrics (Post-Call):\")\n","display(final_test_df)\n","\n","# Plot confusion matrices\n","fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n","for i, (model_name, y_pred, cmap) in enumerate([\n","    ('XGB (0.68)', y_test_pred_xgb, 'Purples'),\n","    ('GBM (0.50)', y_test_pred_gbm, 'Oranges')\n","]):\n","    cm = confusion_matrix(y_test_post, y_pred)\n","    sns.heatmap(cm, annot=True, fmt='d', cmap=cmap, ax=axs[i])\n","    axs[i].set_title(f'{model_name} Confusion Matrix')\n","    axs[i].set_xlabel('Predicted')\n","    axs[i].set_ylabel('Actual')\n","plt.tight_layout()\n","plt.show()\n"],"metadata":{"id":"pNDqS5eZKV-X"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["âœ… **Final Model Choice: XGBoost**\n","\n","Although GBM achieves **higher precision and accuracy**, the business goal for post-call is to:\n","> Maximize the number of **correctly identified subscribers** after contact.\n","\n","- XGBoost delivers **significantly higher recall (0.782)**, with more true positives (TP = 566), while still maintaining a high **accuracy (90.9%)**.\n","- The balance between identifying more subscribers (TP) and acceptable false alarms (FP) makes **XGBoost the superior choice** for optimizing conversion.\n","\n","---\n","### Post-Call: Time Efficiency Analysis\n","\n","To better understand the value of this recall performance in a real-world context, we now break down the modelâ€™s ability to capture true subscribers and highlight its impact on follow-up efficiency.\n"],"metadata":{"id":"Grq_arIhL8J3"}},{"cell_type":"code","source":[" # --- Post-Call Evaluation Summary ---\n","\n","# Final model pipeline\n","final_postcall_pipeline = Pipeline([\n","    ('preprocessing', post_call_preprocessor),\n","    ('classifier', best_xgb1)\n","])\n","\n","# Make predictions using the pipeline:\n","y_prob_post = final_postcall_pipeline.predict_proba(X_test_post)[:, 1]\n","\n","# Define a threshold\n","threshold_post = 0.68\n","\n","# Convert probabilities to class predictions using the threshold\n","y_pred_post = (y_prob_post >= threshold_post).astype(int)\n","\n","# Calculate recall\n","recall_post = recall_score(y_test_post, y_pred_post)\n","print(f\"ðŸ” Post-Call Model Recall: {recall_post:.3f}\")\n","print(f\"âœ… This means we correctly identified {recall_post * 100:.1f}% of all actual subscribers.\")"],"metadata":{"id":"OzC5RbAM3xHg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# TP and FN Breakdown\n","tp_post = ((y_test_post == 1) & (y_pred_post == 1)).sum()\n","fn_post = ((y_test_post == 1) & (y_pred_post == 0)).sum()\n","\n","print(f\"âœ”ï¸ True Positives (Correctly predicted subscribers): {tp_post}\")\n","print(f\"âŒ False Negatives (Missed actual subscribers): {fn_post}\")\n"],"metadata":{"id":"tDstD6kW4JaL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[" ðŸŽ¯ **Post-Call Model Recall Impact**\n","\n","The post-call model was designed to help identify customers **most likely to subscribe** after an interaction, ensuring follow-ups and efforts are focused on high-conversion leads.\n","\n","#### ðŸ“Š Key Metrics:\n","- **Recall**: 78.2% â€” meaning nearly 8 out of 10 real subscribers were correctly identified\n","- **True Positives**: 628 correctly identified subscribers\n","- **False Negatives**: 175 subscribers missed\n","\n","#### ðŸ’¼ Business Value:\n","- High recall minimizes missed opportunities â€” we retain more potential clients who would actually convert.\n","- Combined with time-focused strategies, the model boosts ROI by making post-call follow-up more targeted and effective.\n","\n","---"],"metadata":{"id":"z--mKSHy4O95"}},{"cell_type":"markdown","source":["### Post-Call: Feature Importance Analysis\n","\n","- Extract top features from final model (e.g., XGBoost feature importance).\n","- Highlight which features drove post-call subscription success (duration, campaign, balance, etc.).\n"],"metadata":{"id":"FoUgDLBYN3iA"}},{"cell_type":"code","source":["# --- Feature Importance + Segment Success Analysis (Post-Call) ---\n","\n","# Feature Importance (XGB, Test Set)\n","perm = PermutationImportance(best_xgb1, random_state=seed)\n","perm.fit(X_test_post_processed, y_test_post)\n","\n","# Feature names from preprocessor\n","feature_names = post_call_preprocessor.get_feature_names_out()\n","perm_df = pd.DataFrame({\n","    'Feature': feature_names,\n","    'Importance Mean': perm.feature_importances_,\n","    'Importance Std': perm.feature_importances_std_\n","}).sort_values('Importance Mean', ascending=False)\n","\n","print(\"\\nPermutation Feature Importances (XGB - Test Set):\")\n","display(perm_df.head(10))\n","\n","# Top 10 feature importance plot\n","plt.figure(figsize=(10, 6))\n","sns.barplot(data=perm_df.head(10), x='Importance Mean', y='Feature', palette='Blues_d')\n","plt.title(\"Top 10 Feature Importances (XGB - Test Set)\")\n","plt.xlabel(\"Mean Importance\")\n","plt.ylabel(\"Feature\")\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"QaoguJpHN6zL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### âœ… Post-Call Feature Importance\n","\n","This stage provides interpretability and strategic insight from the final XGBoost model.\n","\n","\n","#### ðŸ” What drives customer subscriptions after the call?\n","\n","- **Top Feature**: `duration` â€” confirming that longer, more engaged calls are more likely to convert.\n","- Other strong predictors include:\n","  - `contact_unknown`, `day`, and certain months (`aug`, `jul`, `nov`)\n","  - These reflect operational and timing factors tied to marketing effectiveness.\n","\n","---\n"],"metadata":{"id":"SMYHrqZwRUMC"}},{"cell_type":"markdown","source":["### Segment-Level Success Rate Analysis"],"metadata":{"id":"S40LpH3iFKR-"}},{"cell_type":"code","source":["# --- Segment-Level Success Rate Analysis ---\n","\n","# Add balance_category to val set (needed for age_balance_segment)\n","def categorize_balance(balance):\n","    if balance < 0:\n","        return 'negative'\n","    elif balance == 0:\n","        return 'zero'\n","    else:\n","        return 'positive'\n","\n","X_val_post['balance_category'] = X_val_post['balance'].apply(categorize_balance)\n","\n","# Predict on validation set\n","val_data_segmented = X_val_post.copy()\n","val_data_segmented['y_true'] = y_val_post.values\n","val_data_segmented['y_pred'] = best_xgb1.predict(X_val_post_processed)\n","\n","# Add composite segments\n","val_data_segmented['segment_combo'] = val_data_segmented['job'].astype(str) + ' | ' + val_data_segmented['education'].astype(str)\n","val_data_segmented['age_balance_segment'] = val_data_segmented['age_group'].astype(str) + ' | ' + val_data_segmented['balance_category'].astype(str)\n","\n","# True Positives\n","true_positives = val_data_segmented[(val_data_segmented['y_true'] == 1) & (val_data_segmented['y_pred'] == 1)]\n","\n","# Segment: job + education\n","segment_combo = true_positives.groupby('segment_combo').size() / val_data_segmented.groupby('segment_combo').size()\n","segment_combo = segment_combo.sort_values(ascending=False).dropna().reset_index()\n","segment_combo.columns = ['Segment', 'Success Rate']\n","segment_combo['Category'] = 'Job | Education'\n","\n","# Segment: age + balance\n","segment_age_balance = true_positives.groupby('age_balance_segment').size() / val_data_segmented.groupby('age_balance_segment').size()\n","segment_age_balance = segment_age_balance.sort_values(ascending=False).dropna().reset_index()\n","segment_age_balance.columns = ['Segment', 'Success Rate']\n","segment_age_balance['Category'] = 'Age + Balance'\n","\n","# Combine segment results\n","combined_segments_post = pd.concat([segment_combo, segment_age_balance], ignore_index=True)\n","\n","# Display combined segment results\n","print(\"\\nTop Segment-Level Success Rates (Post-Call True Positives):\")\n","display(combined_segments_post.head(10))\n","\n","# Plot top 10 segments overall\n","plt.figure(figsize=(10, 6))\n","sns.barplot(data=combined_segments_post.head(10), x='Success Rate', y='Segment', hue='Category', dodge=False)\n","plt.title('Top Post-Call Segments by True Positive Success Rate')\n","plt.xlabel('Success Rate')\n","plt.ylabel('Segment')\n","plt.tight_layout()\n","plt.show()\n","\n","# Separate Plot for Age + Balance Segments (Top 5)\n","top_age_balance = segment_age_balance.head(5)\n","plt.figure(figsize=(8, 4))\n","sns.barplot(data=top_age_balance, x='Success Rate', y='Segment', palette='Blues_d')\n","plt.title('Top Age + Balance Segments (True Positive Success Rate)')\n","plt.xlabel('Success Rate')\n","plt.ylabel('Age + Balance Segment')\n","plt.tight_layout()\n","plt.show()\n","\n"],"metadata":{"id":"OX94TD93ONTI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### âœ… Post-Call Segment Analysis\n","\n","\n","#### ðŸ§­ Which customer segments are most likely to say \"yes\"?\n","\n","- **Top job + education segments**:\n","  - `student | tertiary`\n","  - `retired | tertiary`\n","  - `blue-collar | tertiary`\n","\n","- **Top age + balance segments**:\n","  - `60+ | positive`\n","  - `51-60 | positive`\n","  - These indicate financially stable older clients with good subscription potential.\n","\n","\n","These insights are valuable for refining outreach strategies, improving conversion rates, and focusing resources on high-yield segments.\n","\n","---"],"metadata":{"id":"m9xBCDSiSSgS"}},{"cell_type":"markdown","source":["## ðŸš€ DuckDB Optimization (Bonus)\n","\n","As an additional optimization layer, we demonstrate how DuckDB â€” a lightweight, in-memory SQL engine â€” can efficiently handle large tabular operations directly within the machine learning workflow.\n","\n","This approach improves scalability and performance for real-time data joins, aggregations, and pipeline integration, especially when working with call metadata and customer profiles.\n"],"metadata":{"id":"TDmlRvkU7UTf"}},{"cell_type":"code","source":["# Add predictions and probabilities to test set\n","postcall_df = X_test_post.copy()\n","postcall_df['y_true'] = y_test_post.values\n","postcall_df['y_pred'] = y_pred_post\n","postcall_df['y_prob'] = y_prob_post\n","postcall_df.reset_index(drop=True, inplace=True)\n"],"metadata":{"id":"UOHuWn-K7Tdd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Filter out low-probability \"no\" predictions\n","low_prob_negatives = duckdb.query(\"\"\"\n","    SELECT *\n","    FROM postcall_df\n","    WHERE y_pred = 0 AND y_prob < 0.3\n","\"\"\").to_df()\n","\n","print(f\"ðŸ§¹ Filtered {len(low_prob_negatives)} low-probability non-subscribers\")\n"],"metadata":{"id":"cgJdrXj68zUY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Top high-confidence leads (likely subscribers)\n","high_confidence_yes = duckdb.query(\"\"\"\n","    SELECT *\n","    FROM postcall_df\n","    WHERE y_pred = 1 AND y_prob >= 0.8\n","    ORDER BY y_prob DESC\n","    LIMIT 10\n","\"\"\").to_df()\n","\n","high_confidence_yes.head()\n"],"metadata":{"id":"6BXr_PbE8zCH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Subscribers by age group and job\n","subscribers_by_segment = duckdb.query(\"\"\"\n","    SELECT age, job, y_pred, y_prob\n","    FROM postcall_df\n","    WHERE y_pred = 1 AND y_prob >= 0.6\n","    ORDER BY age\n","\"\"\").to_df()\n","\n","subscribers_by_segment.head()\n"],"metadata":{"id":"i3WP5APW8yr5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define a Quick Filter Function\n","def duck_query(df, sql):\n","    return duckdb.query(sql).to_df()\n","\n","# Example usage:\n","duck_query(postcall_df, \"\"\"\n","    SELECT job, COUNT(*) AS total\n","    FROM postcall_df\n","    WHERE y_pred = 1 AND y_prob >= 0.75\n","    GROUP BY job\n","    ORDER BY total DESC\n","\"\"\")\n"],"metadata":{"id":"szkUBdq29ICQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[" ðŸ¥**Application of DuckDB SQL Filtering**\n","\n","ðŸŽ¯ Objective: To enable SQL-style querying and precise lead targeting on post-call predictions, we integrated DuckDB into our pipeline.\n","This allows for:\n","\n","- Filtering customers by prediction confidence\n","- Isolating high- or low-priority leads\n","- Segmenting subscribers using familiar SQL logic\n","\n","The following cells demonstrate practical business queries that support targeted marketing actions.\n","\n","#### ðŸ” Key Use Cases:\n","- **Filtered out low-confidence non-subscribers**:\n","  - `WHERE y_pred = 0 AND y_prob < 0.3`\n","  - Helped reduce unnecessary follow-ups and operational inefficiencies.\n","  \n","- **Prioritized high-confidence leads**:\n","  - `WHERE y_pred = 1 AND y_prob >= 0.8`\n","  - Enabled targeted engagement with customers most likely to convert.\n","\n","- **Segmented customers by age and job**:\n","  - Discovered strong conversion signals among:\n","    - Younger age groups (18â€“30)\n","    - Professions like management, technician, and blue-collar\n","\n","#### ðŸ’¼ Strategic Value:\n","- Bridges the gap between ML output and marketing strategy\n","- Offers flexible, readable insights through SQL-style queries\n","- Adds interpretability to predictive models without extra modeling complexity\n","\n","DuckDB enabled rapid post-model analysis â€” turning predictions into decisions.\n","___"],"metadata":{"id":"UjaixT9wAz0R"}},{"cell_type":"markdown","source":["## ðŸ” Post-Call Clustering & Segment Profiling\n","\n","- Apply PCA to reduce dimensionality of post-call feature space.\n","- Use hierarchical clustering (Wardâ€™s method) on PCA results.\n","- Assign customers to segments (Cluster 1â€“4).\n","- Calculate subscription rates per cluster.\n","- Annotate and describe each segmentâ€™s business relevance."],"metadata":{"id":"aUH_KqDq6KoD"}},{"cell_type":"code","source":["# --- Post-Call Hierarchical Clustering & Profiling ---\n","\n","\n","# 1. Reduce dimensionality (PCA to 10 components)\n","pca_post = PCA(n_components=10, random_state=seed)\n","X_post_pca = pca_post.fit_transform(X_train_post_processed)\n","\n","# 2. Linkage matrix for dendrogram\n","Z_post = linkage(X_post_pca, method='ward')\n","\n","# 3. Plot dendrogram\n","plt.figure(figsize=(12, 6))\n","plt.title(\"ðŸ” Dendrogram - Post-Call Clustering (Train Set)\")\n","dendrogram(Z_post, truncate_mode='level', p=5)  # Show top 5 levels\n","plt.xlabel(\"Sample Index\")\n","plt.ylabel(\"Cluster Distance\")\n","plt.tight_layout()\n","plt.grid(True)\n","plt.show()\n","\n","# 4. Assign cluster labels (choose 4 as a starting point)\n","clusters_post = fcluster(Z_post, t=4, criterion='maxclust')\n","\n","# 5. Attach cluster & label to original (raw) train data\n","X_train_post_clustered = X_train_post.copy()\n","X_train_post_clustered['cluster'] = clusters_post\n","X_train_post_clustered['y'] = y_train_post.values  # Reattach labels\n","\n","# 6. Cluster-wise Subscription Rates\n","post_cluster_summary = X_train_post_clustered.groupby('cluster')['y'].value_counts(normalize=True).unstack().fillna(0)\n","print(\"\\nPost-Call Cluster Subscription Rates (%):\")\n","print((post_cluster_summary * 100).round(2))\n","\n","# Optional heatmap\n","sns.heatmap((post_cluster_summary * 100).round(2), annot=True, fmt=\".2f\", cmap=\"YlOrRd\")\n","plt.title(\"Post-Call Cluster-wise Subscription Distribution (%)\")\n","plt.ylabel(\"Cluster\")\n","plt.xlabel(\"Subscription Outcome\")\n","plt.show()\n"],"metadata":{"id":"3F2OQmxP9ncH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Mean of Numeric Features\n","X_train_post_clustered.groupby('cluster')[['age', 'duration', 'contact_frequency']].mean().round(2)\n"],"metadata":{"id":"SDo20MKR-69U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Categorical Distributions â€” Job, Month, Contact Type\n","\n","# 1. Job distribution\n","X_train_post_clustered.groupby('cluster')['job'].value_counts(normalize=True).unstack().fillna(0).round(2)\n"],"metadata":{"id":"03LtEgyB-611"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 2. Month of contact\n","X_train_post_clustered.groupby('cluster')['month'].value_counts(normalize=True).unstack().fillna(0).round(2)"],"metadata":{"id":"uDLPYd2L3gaK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 3. Contact type\n","X_train_post_clustered.groupby('cluster')['contact'].value_counts(normalize=True).unstack().fillna(0).round(2)"],"metadata":{"id":"t2G7gzC-3rEi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### ðŸ“‹ **Post-Call Clustering & Segment Summary**\n","\n","Using PCA and hierarchical clustering, customers were grouped into four distinct behavioral segments based on call metadata and demographic features.\n","\n","Cluster-wise subscription rates were calculated to evaluate segment-level success:\n","\n","| Cluster | % No | % Yes | Notes |\n","|:-------:|:----:|:-----:|:------|\n","| 1 | 91.64% | 8.36% | Low conversion segment |\n","| 2 | 96.05% | 3.95% | Highly resistant group |\n","| 3 | 65.24% | 34.76% | â­ High-converting cluster |\n","| 4 | 96.36% | 3.64% | Most resistant group |\n","\n","\n","\n","### ðŸ§  Cluster Insights:\n","\n","- **Cluster 3 â€“ High-Converting Group**:\n","  - Stands out with a 34.76% conversion rate.\n","  - Characterized by:\n","    - Longer call durations,\n","    - Moderate campaign frequency,\n","    - Higher balance values,\n","    - Financial stability (low loan burden).\n","  - Majority fall within the **30â€“40 age group**, consistent with earlier trends seen in preliminary segment success analysis.\n","  - This behavioral diversity explains why Cluster 3 appeared as multiple dense regions in t-SNE and UMAP projections.\n","\n","- **Cluster 1 â€“ Moderate Group**:\n","  - Some success (~8% conversions).\n","  - Customers generally engaged through campaigns occurring in May and November.\n","  - Financially mixed profiles.\n","\n","- **Clusters 2 & 4 â€“ Highly Resistant Segments**:\n","  - Very low subscription rates (~3â€“4%).\n","  - Exhibited signs of campaign fatigue (multiple contact attempts with low response).\n","  - Higher financial burden markers observed.\n","\n","\n","- The clustering approach thus validated and enriched earlier static segment findings, providing a deeper behavioral and actionable view of customer groups.\n","\n","Having profiled the clusters based on behavioral and demographic traits, we now turn to visualizing their distribution in reduced-dimensional spaces.  \n","This step helps reveal the underlying structure, cohesion, and separability of the identified customer segments.\n","\n","---"],"metadata":{"id":"tcqKwfoVBQwT"}},{"cell_type":"markdown","source":["## ðŸŽ¨ Cluster Visualization Summary (PCA, t-SNE, UMAP)\n","\n","- Visualize cluster structure using three projection methods:\n","  - **PCA** â€“ linear separation and variance interpretation.\n","  - **t-SNE** â€“ local cohesion and sub-cluster detection.\n","  - **UMAP** â€“ balance between global and local structure.\n","- Highlight spatial dominance and variation of Cluster 3.\n","- Comment on how visual dispersion supports behavioral complexity in segments."],"metadata":{"id":"6uaq0MR_9s6g"}},{"cell_type":"code","source":["# save X_train dataset\n","joblib.dump(X_train_post_clustered, 'X_train_post_clustered.joblib')"],"metadata":{"id":"rUMyYnFbA4GM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load the clustered data\n","data = load('X_train_post_clustered.joblib')\n","X = data.drop(columns=['cluster', 'y'])\n","y = data['cluster']\n","\n","# Preprocessing pipeline\n","num_features = ['age', 'balance', 'duration', 'day', 'campaign', 'total_loans', 'contact_frequency']\n","cat_features = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month',\n","                'age_group', 'call_duration_category', 'age_financial_burden']\n","\n","preprocessor = ColumnTransformer([\n","    ('num', Pipeline([('imp', SimpleImputer()), ('scale', RobustScaler())]), num_features),\n","    ('cat', Pipeline([('imp', SimpleImputer(strategy='most_frequent')),\n","                      ('enc', OneHotEncoder(drop='first', sparse=False))]), cat_features)\n","])\n","\n","X_proc = preprocessor.fit_transform(X)\n","\n","# PCA\n","pca = PCA(n_components=2, random_state=seed)\n","X_pca = pca.fit_transform(X_proc)\n","\n","# t-SNE\n","tsne = TSNE(n_components=2, random_state=seed)\n","X_tsne = tsne.fit_transform(X_proc)\n","\n","# Plot\n","def plot_clusters(X, labels, title):\n","    plt.figure(figsize=(8, 6))\n","    sns.scatterplot(x=X[:, 0], y=X[:, 1], hue=labels, palette='tab10', s=50, edgecolor='k')\n","    plt.title(title)\n","    plt.grid(True)\n","    plt.tight_layout()\n","    plt.show()\n","\n","plot_clusters(X_pca, y, \"PCA - Post-Call Clusters\")\n","plot_clusters(X_tsne, y, \"t-SNE - Post-Call Clusters\")\n"],"metadata":{"id":"XE3EsfZ2Lhj0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# UMap display\n","umap_2d = umap.UMAP(n_components=2, random_state=seed)\n","X_umap = umap_2d.fit_transform(X_proc)\n","\n","# Plotting\n","# Use 'y' instead of 'cluster_labels' as 'y' holds the cluster labels\n","sns.scatterplot(x=X_umap[:, 0], y=X_umap[:, 1], hue=y, palette='tab10')\n","plt.title(\"UMAP - Post-Call Clusters\")\n","plt.grid(True)\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"uFtP1T0DMMi_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### ðŸ“‹ **Cluster Visualization Findings (PCA, t-SNE, UMAP)**\n","\n","\n","To better understand the spatial distribution and separability of the post-call customer clusters, we applied three dimensionality reduction techniques:\n","\n","### ðŸ“ˆ 1. Principal Component Analysis (PCA)\n","- PCA revealed clear **linear separation** between clusters based on the major axes of variance.\n","- **Cluster 3** dominated a distinct region in the bottom-left quadrant of the PCA plot, reinforcing its behavioral uniqueness.\n","\n","### ðŸŒŒ 2. t-SNE (t-distributed Stochastic Neighbor Embedding)\n","- t-SNE emphasized **local similarities**.\n","- Cluster 3 appeared as multiple dense subgroups scattered across the space, suggesting internal diversity within the top-performing cluster.\n","- Other clusters showed more dispersed or overlapping patterns, consistent with their lower conversion rates.\n","\n","### ðŸŒ 3. UMAP (Uniform Manifold Approximation and Projection)\n","- UMAP balanced global and local relationships.\n","- Cluster 3 occupied **specific but non-exclusive zones**, indicating that while members share strong behavioral traits, they are still connected to broader customer behaviors.\n","- This visualization highlights the **complexity** and **potential richness** within the high-converting segment.\n","\n","---\n","\n","### ðŸ” Interpretation Summary\n","- **Cluster 3** shows the strongest behavioral cohesion across all three projections, but with internal sub-structure worth exploring in future campaigns.\n","- **Clusters 2 and 4** were consistently separated from high-performing regions, reinforcing their classification as low-value targets.\n","- Visualization confirms that behavioral segmentation **provides deeper targeting value** than simple demographic segmentation alone.\n","\n","These insights can directly inform future campaign targeting, customer journey mapping, and personalized offer design.\n"],"metadata":{"id":"I53ynpzOaUna"}},{"cell_type":"code","source":["#      --- Final Pipelines ---\n","\n","# Create the pre-call pipeline\n","final_precall_pipeline = Pipeline([\n","    ('preprocessing', pre_call_preprocessor),\n","    ('classifier', compnb_model)\n","])\n","\n","# Save final ComplementNB pre-call pipeline\n","dump(compnb_pipeline, 'final_precall_pipeline.joblib')\n","print(\"Final Pre-Call model pipeline saved as 'final_precall_pipeline.joblib'\")\n","\n","\n","# Create the post-call pipeline if it doesn't exist\n","final_postcall_pipeline = Pipeline([\n","    ('preprocessing', post_call_preprocessor), # Assuming post_call_preprocessor is defined\n","    ('classifier', best_xgb1)\n","])\n","\n","# Save final XGBoost post-call pipeline\n","dump(final_postcall_pipeline, 'final_postcall_pipeline.joblib')\n","print(\"Final Post-Call model pipeline saved as 'final_postcall_pipeline.joblib'\")"],"metadata":{"id":"u0R3_jwF468w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load Pre-Call Model\n","prec_model = load('final_precall_pipeline.joblib')\n","\n","# Load Post-Call Model\n","post_model = load('final_postcall_pipeline.joblib')\n"],"metadata":{"id":"8N58S0U36Iel"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","### ðŸ“Œ Post-Call Phase Summary\n","\n","The post-call model was designed to identify customers most likely to **subscribe after a call**. It incorporated call metadata and enriched demographic features.\n","\n","#### ðŸ“Œ Final Model: XGBoost Classifier (threshold-tuned)\n","- **F1 Score (Test Set)**: 0.749\n","- **Precision**: High â€” minimized false positives\n","- **Cross-validation**: 5-fold with ADASYN balancing\n","- **Threshold tuning**: Applied to optimize performance at class level\n","\n","#### âš™ï¸ Post-Call Strategic Role\n","- Best suited for **targeted follow-up** after initial contact.\n","- Highly effective at capturing complex, nonlinear patterns in customer response behavior.\n","- Aligned with marketing goals to **maximize conversions per campaign dollar**.\n","\n","#### ðŸ”‘ Key Features Driving Performance\n","- `duration` â€” longer, meaningful conversations correlated with positive outcomes.\n","- `campaign` â€” fewer repeated calls improved success rates.\n","- `balance` â€” financial standing remains a powerful indicator.\n","- Age and loan-based burden markers (`age_financial_burden_*`) contributed subtly.\n","\n","#### ðŸŽ¯ Outcome\n","- XGBoost successfully segmented customers into four behavioral clusters.\n","- **Cluster 3 emerged as the top-performing group**, with a subscription rate of **34.76%**.\n","- Insights from this model can guide **call prioritization, campaign timing, and offer structuring**.\n","\n","---\n","---"],"metadata":{"id":"orHip6sZbDa-"}},{"cell_type":"markdown","source":["## ðŸ’¼ Final Project Conclusion & Business Recommendations\n","\n","This final section summarizes the key outcomes of both the Pre-Call and Post-Call modeling phases, highlighting their strategic value in driving efficient and effective term deposit campaigns.\n","\n","It also presents actionable recommendations for how the models, insights, and customer segments can be applied in a real-world marketing context â€” transforming predictive analytics into targeted decision-making.\n","\n","\n","### ðŸŽ¯ Project Recap\n","\n","This project tackled the problem of optimizing term deposit campaign targeting using a two-stage modeling approach:\n","\n","- **Pre-Call Phase**: Identify customers unlikely to subscribe before initiating contact.\n","- **Post-Call Phase**: Predict likelihood of subscription after the call, based on metadata from the interaction.\n","\n","By combining business context, machine learning models, class imbalance strategies, and cluster-based behavioral segmentation, this solution provides a robust framework for intelligent marketing execution.\n","\n","---\n","\n","### ðŸ” Strategic Value of the Two-Phase Workflow\n","\n","- **Pre-Call Model**:\n","  - Filters out customers least likely to convert.\n","  - Helps reduce call center load and campaign expenditure.\n","  - Informs exclusion strategies based on segments (e.g., age 60+, students with no loan burden).\n","\n","- **Post-Call Model**:\n","  - Accurately identifies high-conversion potential after real engagement.\n","  - Prioritizes follow-ups for Cluster 3 â€” the highest-yield customer group.\n","  - Optimizes resource usage by focusing human effort on warm leads.\n","\n","Together, the two phases provide a **full-funnel targeting system**, balancing efficiency (Pre-Call) with effectiveness (Post-Call).\n","\n","---\n","\n","### ðŸ” Key Insights\n","\n","- **Call Duration**, **Campaign Count**, and **Balance** are critical predictors of subscription.\n","- Cluster analysis revealed behavioral groups, with **Cluster 3** delivering a 34.76% conversion rate.\n","- t-SNE and UMAP visuals highlighted that Cluster 3 is behaviorally diverse â€” an opportunity for personalized offers.\n","- Using threshold tuning, we maximized recall and F1 in both phases, aligning modeling to business needs.\n","\n","---\n","\n","### âš™ï¸ Deployment Notes\n","\n","- Final models are wrapped in scikit-learn pipelines, ensuring preprocessing consistency.\n","- Models are saved using `joblib` and can be deployed as standalone scoring components or integrated into APIs.\n","- Customer segments can be dynamically assigned using the clustering logic for personalization in real-time systems.\n","- DuckDB demonstrates potential for scalable, in-memory analytics integration during pipeline execution.\n","\n","---\n","\n","### ðŸ“Œ Business Recommendations\n","\n","1. **Implement Pre-Call Filtering**:\n","   - Use the Pre-Call model to exclude low-potential segments before outreach.\n","   - Focus campaign budget on customers who haven't historically said \"no\".\n","\n","2. **Prioritize Post-Call Prospects**:\n","   - Use the Post-Call model to prioritize Cluster 3 members for follow-up.\n","   - Allocate agent time to high-yield leads to increase conversion ROI.\n","\n","3. **Optimize Campaign Frequency**:\n","   - Reduce repeated calls â€” fewer campaign touches improved outcomes.\n","   - Test ideal contact thresholds with A/B testing.\n","\n","4. **Segment-Based Personalization**:\n","   - Tailor offers for different behavioral clusters.\n","   - Use age group, loan burden, and past response patterns for message customization.\n","\n","5. **Monitor & Recalibrate**:\n","   - Retrain models quarterly to adapt to changing customer behavior.\n","   - Track feature drift and adjust thresholds as needed.\n","\n","---\n","\n","âœ… This project demonstrates how strategic machine learning can bridge business goals and operational efficiency. The result is a lean, data-driven, and deployable marketing engine ready for real-world impact.\n"],"metadata":{"id":"dXDFLKFHmLIM"}},{"cell_type":"code","source":[],"metadata":{"id":"SCVtap-Bo0Gu"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNGaYvVftOOqJgj7hCZ6+/k"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}